{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a357ec2-2833-4dbe-ae72-1de683c5ab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1]\n",
      "{0: array([(7, 4, 4, 8, 6), (6, 1, 1, 8, 6), (6, 0, 0, 8, 6)],\n",
      "      dtype=[('recipient_parent_node', '<i4'), ('recipient_child_node', '<i4'), ('leaf', '<i4'), ('donor_parent_node', '<i4'), ('donor_child_node', '<i4')])}\n",
      "[(5, 2), (5, 1), (6, 0), (6, 5), (7, 3), (7, 4), (8, 7), (8, 6)]\n",
      "0 {'node_time': 0.0, 'level': 0, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': False, 'num_leaves_below': 1, 'num_leaves_below_gene_present': 1}\n",
      "1 {'node_time': 0.0, 'level': 0, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 1., 0.,  ..., 0., 0., 0.]), 'update_needed': False, 'num_leaves_below': 1, 'num_leaves_below_gene_present': 1}\n",
      "2 {'node_time': 0.0, 'level': 0, 'gene_presence': 0, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([-1., -1., -1.,  ..., -1., -1., -1.]), 'update_needed': False, 'num_leaves_below': 1, 'num_leaves_below_gene_present': 0}\n",
      "3 {'node_time': 0.0, 'level': 0, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 1., 0.,  ..., 0., 0., 0.]), 'update_needed': False, 'num_leaves_below': 1, 'num_leaves_below_gene_present': 1}\n",
      "4 {'node_time': 0.0, 'level': 0, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 1., 0.,  ..., 0., 0., 0.]), 'update_needed': False, 'num_leaves_below': 1, 'num_leaves_below_gene_present': 1}\n",
      "5 {'node_time': 0.03433473780751228, 'level': 1, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 2, 'num_leaves_below_gene_present': 1}\n",
      "6 {'node_time': 0.5720720291137695, 'level': 2, 'gene_presence': 1, 'recipient': {'is_parent_node': True, 'events': [((6, 1), (8, 6)), ((6, 0), (8, 6))]}, 'donor': {'is_child_node': True, 'events': [((7, 4), (8, 6)), ((6, 1), (8, 6)), ((6, 0), (8, 6))]}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 3, 'num_leaves_below_gene_present': 2}\n",
      "7 {'node_time': 0.7739391326904297, 'level': 1, 'gene_presence': 1, 'recipient': {'is_parent_node': True, 'events': [((7, 4), (8, 6))]}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 2, 'num_leaves_below_gene_present': 2}\n",
      "8 {'node_time': 0.9128420948982239, 'level': 3, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 5, 'num_leaves_below_gene_present': 4}\n",
      "tensor([[   0,  206, 1500,  368,  226],\n",
      "        [ 206,    0, 1500,  310,   64],\n",
      "        [1500, 1500,    0, 1500, 1500],\n",
      "        [ 368,  310, 1500,    0,  332],\n",
      "        [ 226,   64, 1500,  332,    0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/3738863879.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edges = torch.tensor(graph_properties[1], dtype=torch.long)  # [2, num_edges]\n",
      "/tmp/ipykernel_45/3738863879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coords = torch.tensor(graph_properties[2].T)             # [2, num_nodes]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import pickle\n",
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, ReLU, Dropout, BatchNorm1d\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "def one_hot_encode(sequences, gene_present, max_number_of_snps, alphabet=['A','C','T','G','-']):\n",
    "    \"\"\"\n",
    "    sequences: List of strings (DNA sequences)\n",
    "    gene_present: np.array(bool) oder Torch Tensor, gleiche Länge wie sequences\n",
    "    max_number_of_snps: int, fixe Länge für das Hot-Encoding\n",
    "    alphabet: list, Zeichenalphabet\n",
    "    \"\"\"\n",
    "    num_samples = len(sequences)\n",
    "    num_chars = len(alphabet)\n",
    "    char_to_idx = {c:i for i,c in enumerate(alphabet)}\n",
    "    sequences_str = [s.decode('utf-8') for s in sequences]\n",
    "    gene_present = np.array(gene_present, dtype=bool)\n",
    "    \n",
    "    # 1️⃣ Leere Batch-Matrix vorbereiten: (num_samples, max_number_of_snps, num_chars)\n",
    "    batch = np.zeros((num_samples, max_number_of_snps, num_chars), dtype=np.float32)\n",
    "    \n",
    "    # 2️⃣ Hot-Encode alle Sequenzen\n",
    "    for i, seq in enumerate(sequences_str):\n",
    "        if gene_present[i]:\n",
    "            L = min(len(seq), max_number_of_snps)  # abschneiden\n",
    "            for j, c in enumerate(seq[:L]):\n",
    "                if c in char_to_idx:\n",
    "                    batch[i, j, char_to_idx[c]] = 1.0\n",
    "        elif gene_present[i] == 0:\n",
    "            batch[i, :, :] = -1.0\n",
    "            \n",
    "    # 3️⃣ Zufällige, aber konsistente Spaltenpermutation\n",
    "    perm = np.random.permutation(max_number_of_snps)\n",
    "    batch = batch[:, perm, :]\n",
    "    \n",
    "    # 4️⃣ Optional: Flatten zu Vektor (num_samples, max_number_of_snps*num_chars)\n",
    "    batch_flat = batch.reshape(num_samples, -1)\n",
    "    \n",
    "    return torch.tensor(batch_flat)  # shape: (num_samples, max_number_of_snps*num_chars)\n",
    "\n",
    "\n",
    "def load_file(file, max_number_of_snps = 300):\n",
    "    \n",
    "    with h5py.File(file, \"r\") as f:\n",
    "            grp = f[\"results\"]\n",
    "            # Load graph_properties (pickle stored in dataset)\n",
    "            graph_properties = pickle.loads(grp[\"graph_properties\"][()])\n",
    "    \n",
    "            # Unpack graph properties\n",
    "            nodes = torch.tensor(graph_properties[0])                # [num_nodes]\n",
    "            edges = torch.tensor(graph_properties[1], dtype=torch.long)  # [2, num_edges]\n",
    "            coords = torch.tensor(graph_properties[2].T)             # [2, num_nodes]\n",
    "    \n",
    "            gene_absence_presence_matrix = grp[\"gene_absence_presence_matrix\"][()]\n",
    "            nucleotide_sequences = grp[\"nucleotide_sequences\"][()]\n",
    "            #children_gene_nodes_loss_events = grp[\"children_gene_nodes_loss_events\"][()]\n",
    "\n",
    "            if gene_absence_presence_matrix.ndim == 2:\n",
    "                raise ValueError(\n",
    "                    f\"Mehrere Gene gefunden (Matrix-Shape: {gene_absence_presence_matrix.shape}). \"\n",
    "                    \"Dieses Skript ist nur für ein einzelnes Gen ausgelegt.\"\n",
    "                )\n",
    "\n",
    "        \n",
    "            ##### Construct the graph\n",
    "        \n",
    "            G = nx.DiGraph()\n",
    "            \n",
    "            ### Füge Knoten hinzu (mit zugehörigen Zeiten)\n",
    "            node_id_list = nodes.tolist()\n",
    "            sorted_indices = sorted(range(len(node_id_list)), key=lambda i: node_id_list[i])\n",
    "            sorted_node_ids = [node_id_list[i] for i in sorted_indices]\n",
    "            \n",
    "            for new_i, orig_i in enumerate(sorted_indices):\n",
    "                node_id = node_id_list[orig_i]\n",
    "                G.add_node(node_id, node_time=coords[:, orig_i].tolist()[5])\n",
    "\n",
    "            \n",
    "            ### Füge Kanten hinzu\n",
    "            edge_list = edges.tolist()\n",
    "            for src, dst in zip(edge_list[0], edge_list[1]):\n",
    "                G.add_edge(src, dst)\n",
    "\n",
    "            ### Tiefe der Nodes: Blätter habe Tiefe 0\n",
    "            level = {n: 0 for n in G.nodes}\n",
    "            for node in reversed(list(nx.topological_sort(G))):\n",
    "                successors = list(G.successors(node))\n",
    "                if successors:\n",
    "                    level[node] = 1 + max(level[s] for s in successors)\n",
    "            nx.set_node_attributes(G, level, \"level\")\n",
    "\n",
    "            \"\"\"\n",
    "            ### Füge gene presence hinzu\n",
    "            \n",
    "            gene_presence = {}\n",
    "\n",
    "            for i, node in enumerate(G.nodes()):\n",
    "                if i < len(gene_absence_presence_matrix):\n",
    "                    gene_presence[node] = gene_absence_presence_matrix[i]\n",
    "                else:\n",
    "                    gene_presence[node] = 1\n",
    "            \n",
    "            nx.set_node_attributes(G, gene_presence, \"gene_presence\")\n",
    "            \"\"\"\n",
    "        \n",
    "            ### Integriere HGT information\n",
    "\n",
    "            # Initialisierung:\n",
    "            default_hgt_events = {\n",
    "                node: {\n",
    "                    \"recipient\": {\"is_parent_node\": False, \"events\": []},\n",
    "                    \"donor\":      {\"is_child_node\":  False, \"events\": []}\n",
    "                }\n",
    "                for node in G.nodes()\n",
    "            }\n",
    "            nx.set_node_attributes(G, default_hgt_events)\n",
    "        \n",
    "            hgt_events = {}\n",
    "            hgt_grp_simpl = grp.get(\"nodes_hgt_events_simplified\", None)\n",
    "            if hgt_grp_simpl is not None:\n",
    "                for site_id in hgt_grp_simpl.keys():\n",
    "                    hgt_events[int(site_id)] = hgt_grp_simpl[site_id][()]\n",
    "            else:\n",
    "                hgt_events = {}\n",
    "\n",
    "            if hgt_events:\n",
    "                for event in hgt_events[0]:\n",
    "                    recipient_parent_node = int(event['recipient_parent_node'])\n",
    "                    recipient_child_node  = int(event['recipient_child_node'])\n",
    "                    donor_parent_node     = int(event['donor_parent_node'])\n",
    "                    donor_child_node      = int(event['donor_child_node'])\n",
    "        \n",
    "                    hgt_event = ((recipient_parent_node, recipient_child_node),\n",
    "                                 (donor_parent_node, donor_child_node))\n",
    "        \n",
    "                    # recipient parent: Flag setzen und Event anhängen\n",
    "                    G.nodes[recipient_parent_node][\"recipient\"][\"is_parent_node\"] = True\n",
    "                    G.nodes[recipient_parent_node][\"recipient\"][\"events\"].append(hgt_event)\n",
    "        \n",
    "                    # donor child: Flag setzen und Event anhängen\n",
    "                    G.nodes[donor_child_node][\"donor\"][\"is_child_node\"] = True\n",
    "                    G.nodes[donor_child_node][\"donor\"][\"events\"].append(hgt_event)\n",
    "                \n",
    "\n",
    "\n",
    "            ### Add hot encoded nucleotide sequences\n",
    "        \n",
    "            hot_encoded_nucleotide_sequences = one_hot_encode(nucleotide_sequences, gene_absence_presence_matrix, max_number_of_snps)\n",
    "            pad_rows = len(nodes) - len(nucleotide_sequences) # Fill the remaining nodes with zeros.\n",
    "            pad = torch.zeros((pad_rows, hot_encoded_nucleotide_sequences.shape[1]), dtype=hot_encoded_nucleotide_sequences.dtype)\n",
    "            sequences = torch.cat([hot_encoded_nucleotide_sequences, pad], dim=0) # Dimension: [num_nodes, 5 * max_number_of_snps]\n",
    "            sequences_dict = {node: sequences[i] for i, node in enumerate(G.nodes())}\n",
    "            nx.set_node_attributes(G, sequences_dict, \"sequences\")\n",
    "\n",
    "            ### Add a flag for nodes where the sequences have to be processed and the information how many leaves are below this node \n",
    "            ### and how many of them have the gene present.\n",
    "\n",
    "            for node in G.nodes():\n",
    "                children = list(G.successors(node))\n",
    "                is_leaf = len(children) == 0\n",
    "            \n",
    "                # Update-Flag: True, falls der Knoten Kinder hat\n",
    "                G.nodes[node]['update_needed'] = not is_leaf\n",
    "            \n",
    "                if is_leaf:  # Leaf node\n",
    "                    G.nodes[node]['num_leaves_below'] = 1\n",
    "                    # Presence nur, wenn leaf\n",
    "                    G.nodes[node]['num_leaves_below_gene_present'] = int(gene_absence_presence_matrix[node])\n",
    "                else:\n",
    "                    # Summe über Kinder\n",
    "                    G.nodes[node]['num_leaves_below'] = sum(G.nodes[child]['num_leaves_below'] for child in children)\n",
    "                    G.nodes[node]['num_leaves_below_gene_present'] = sum(G.nodes[child]['num_leaves_below_gene_present'] for child in children)\n",
    "\n",
    "            print(gene_absence_presence_matrix)\n",
    "            print(hgt_events)\n",
    "            print(G.edges)\n",
    "\n",
    "    return G\n",
    "\n",
    "folder = \"/mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)\"\n",
    "\n",
    "#files = [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "\"\"\"\n",
    "if len(files) > 1:\n",
    "    files = random.sample(files, 1)\n",
    "\n",
    "list_of_Data = []\n",
    "for f in files:\n",
    "    try:\n",
    "        d = load_file(f)\n",
    "        list_of_Data.append(d)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden von {f}: {e}\")\n",
    "\"\"\"\n",
    "file = random.choice(files)\n",
    "example = load_file(file)\n",
    "\n",
    "#print(f\"{len(list_of_Data)} Dateien erfolgreich geladen.\")\n",
    "\n",
    "for node, attrs in example.nodes(data=True):\n",
    "    print(node, attrs)\n",
    "\n",
    "G = example\n",
    "\n",
    "nodes_to_compare = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Sequenzen extrahieren und zu einem Tensor stapeln\n",
    "seqs = torch.stack([G.nodes[n][\"sequences\"] for n in nodes_to_compare])\n",
    "\n",
    "# Pairwise Hamming-Distanzen:\n",
    "# Unterschied in jedem Feature -> abs diff, dann summieren\n",
    "# seqs.shape = [5, L]\n",
    "# Ergebnis: [5, 5]\n",
    "pairwise_hamming = (seqs.unsqueeze(1) != seqs.unsqueeze(0)).sum(dim=2)\n",
    "\n",
    "print(pairwise_hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57c49d7b-32db-4901-8abf-c6b4fd0032b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n",
      "{}\n",
      "[(5, 3), (5, 4), (6, 0), (6, 1), (7, 2), (7, 5), (8, 6), (8, 7)]\n",
      "5 {'node_time': 0.2329883724451065, 'level': 1, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 2, 'num_leaves_below_gene_present': 2}\n",
      "6 {'node_time': 0.3208651840686798, 'level': 1, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 2, 'num_leaves_below_gene_present': 2}\n",
      "7 {'node_time': 0.7839022278785706, 'level': 2, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 3, 'num_leaves_below_gene_present': 3}\n",
      "8 {'node_time': 0.9147357940673828, 'level': 3, 'gene_presence': 1, 'recipient': {'is_parent_node': False, 'events': []}, 'donor': {'is_child_node': False, 'events': []}, 'sequences': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'update_needed': True, 'num_leaves_below': 5, 'num_leaves_below_gene_present': 5}\n",
      "0 tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "False\n",
      "1 tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "False\n",
      "2 tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "False\n",
      "3 tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "False\n",
      "4 tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "False\n",
      "5 tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "False\n",
      "6 tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "False\n",
      "7 tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "False\n",
      "8 tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/3738863879.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edges = torch.tensor(graph_properties[1], dtype=torch.long)  # [2, num_edges]\n",
      "/tmp/ipykernel_45/3738863879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coords = torch.tensor(graph_properties[2].T)             # [2, num_nodes]\n"
     ]
    }
   ],
   "source": [
    "def aggregate_sequences(G: nx.DiGraph, recalc_all: bool = False, device: str = 'cpu') -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Aggregiere die Node-Sequenzen von den Blättern nach oben.\n",
    "    Jeder interne Knoten erhält das elementweise Maximum seiner Kindersequenzen.\n",
    "\n",
    "    Args:\n",
    "        G: gerichteter Baum (networkx.DiGraph), erwartet Node-Attribute:\n",
    "           - 'sequences': 1D-Tensor (torch.Tensor) pro Node, gleiche Länge für alle Nodes.\n",
    "           - 'level': int\n",
    "           - 'update_needed': bool (optional)\n",
    "        recalc_all: bool, True -> berechne alle internen Knoten neu,\n",
    "                          False -> nur Knoten mit update_needed == True\n",
    "        device: 'cpu' oder 'cuda' (wenn verfügbar)\n",
    "\n",
    "    Returns:\n",
    "        num_updated: Anzahl der Knoten, deren 'sequences' neu berechnet wurden.\n",
    "    \"\"\"\n",
    "    # Liste Nodes in stabiler Reihenfolge\n",
    "    nodes = list(G.nodes())\n",
    "    num_nodes = len(nodes)\n",
    "\n",
    "    # Hole die Länge der Sequenzen\n",
    "    seq_len = G.nodes[nodes[0]].get('sequences', None).shape[0]\n",
    "\n",
    "    # Baue einen großen Tensor mit allen Sequenzen (für vektorisierte Operationen)\n",
    "    # Achtung: wir kopieren hier Daten; das ist absichtlich für Batch-Operationen.\n",
    "    seqs_all = torch.stack([G.nodes[n]['sequences'].to(device) for n in nodes], dim=0)  # shape: [num_nodes, seq_len]\n",
    "\n",
    "    # Gruppiere Knoten nach level\n",
    "    levels = nx.get_node_attributes(G, 'level')\n",
    "    max_level = max(levels.values())\n",
    "\n",
    "    # Erzeuge Kind-Index-Listen: children[node_idx] -> List[int]\n",
    "    children = [[] for _ in range(num_nodes)]\n",
    "    for parent in nodes:\n",
    "        for child in G.successors(parent):\n",
    "            children[parent].append(child)\n",
    "\n",
    "    # Prozessiere level-weise von niedrigstem Level (Blätter, level=0) nach oben: wir brauchen\n",
    "    # nur interne Knoten, also level>=1. Für Aggregation gehen wir von den Kindern herauf, damit die\n",
    "    # Kinder bereits final sind, wenn wir einen Parent berechnen.\n",
    "    for lvl in range(1, max_level + 1):\n",
    "        # Nodes auf diesem level in der selben Reihenfolge wie nodes-liste\n",
    "        nodes_on_level = [n for n in nodes if levels[n] == lvl]\n",
    "        if not nodes_on_level:\n",
    "            raise ValueError(\n",
    "                f\"Level {lvl.shape} is without nodes.\"\n",
    "            )\n",
    "\n",
    "        # Entscheide, welche Knoten tatsächlich neu berechnet werden sollen\n",
    "        if recalc_all:\n",
    "            to_recalc = nodes_on_level\n",
    "        else:\n",
    "            to_recalc = []\n",
    "            for node in nodes_on_level:\n",
    "                if bool(G.nodes[node].get('update_needed', True)):\n",
    "                    to_recalc.append(node)\n",
    "\n",
    "        # Vectorized: baue zwei index-Arrays für Kind0 und Kind1\n",
    "        child0_idxs = [children[i][0] for i in to_recalc]\n",
    "        child1_idxs = [children[i][1] for i in to_recalc]\n",
    "\n",
    "        child0 = seqs_all[torch.tensor(child0_idxs, dtype=torch.long, device=device)]  # [batch, seq_len]\n",
    "        child1 = seqs_all[torch.tensor(child1_idxs, dtype=torch.long, device=device)]\n",
    "\n",
    "        # elementweises Maximum über die beiden Kinder\n",
    "        new_seqs = torch.maximum(child0, child1)  # [batch, seq_len]\n",
    "\n",
    "        # Schreibe die Ergebnisse zurück in seqs_all (und in den Graph)\n",
    "        for out_pos, node in enumerate(to_recalc):\n",
    "            seqs_all[node] = new_seqs[out_pos]\n",
    "            G.nodes[node]['sequences'] = new_seqs[out_pos].detach().cpu()\n",
    "            # update flag zurücksetzen\n",
    "            G.nodes[node]['update_needed'] = False\n",
    "\n",
    "    return G\n",
    "\n",
    "# file = random.choice(files)\n",
    "G = load_file(file)\n",
    "\n",
    "for node, attrs in G.nodes(data=True):\n",
    "    if node > 4:\n",
    "        print(node, attrs)\n",
    "        \n",
    "aggregate_sequences(G)\n",
    "\n",
    "for node, attrs in G.nodes(data=True):\n",
    "    if node > -1:\n",
    "        seq = attrs.get(\"sequences\", None)\n",
    "        if seq is not None:\n",
    "            print(node, seq[:50])   # nur die ersten 50 Stellen\n",
    "        print(attrs.get(\"update_needed\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184d556f-9649-4c93-98a6-234dab195b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "print(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d23bfb50-eb52-4d6f-9e8e-5545ae0adee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 10 + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
