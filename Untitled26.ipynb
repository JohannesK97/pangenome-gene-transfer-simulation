{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b797e83a-b88e-4e8f-a3cf-8ba70cfa482f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kippnich/miniconda3/envs/pangenome-hgt-sim/lib/python3.12/site-packages/numpy/core/getlimits.py:542: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MessagePassing' from 'torch_geometric.data' (/home/kippnich/miniconda3/envs/pangenome-hgt-sim/lib/python3.12/site-packages/torch_geometric/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mDataLoader\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reload\n\u001b[1;32m      3\u001b[0m reload(DataLoader)\n",
      "File \u001b[0;32m/mnt/c/Users/uhewm/OneDrive/PhD/Project No.2/pangenome-gene-transfer-simulation/DataLoader.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data, MessagePassing\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MessagePassing' from 'torch_geometric.data' (/home/kippnich/miniconda3/envs/pangenome-hgt-sim/lib/python3.12/site-packages/torch_geometric/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "import DataLoader\n",
    "from importlib import reload\n",
    "reload(DataLoader)\n",
    "import os\n",
    "import random\n",
    "\n",
    "folder = \"/mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)\"\n",
    "\n",
    "files = [entry.path for entry in os.scandir(folder) if entry.is_file()]\n",
    "\n",
    "if len(files) > 10000:\n",
    "    files = random.sample(files, 10000)\n",
    "\n",
    "data_graphs = []\n",
    "for f in files:\n",
    "    try:\n",
    "        d = DataLoader.load_file(f)\n",
    "        DataLoader.aggregate_sequences(d)\n",
    "        data_graphs.append(d)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden von {f}: {e}\")\n",
    "\n",
    "data = []\n",
    "for G in data_graphs:\n",
    "    try:\n",
    "        dat = DataLoader.graph_to_dataset(G)\n",
    "        data.append(dat)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden von {G}: {e}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for node, attrs in data_graphs[0].nodes(data=True):\n",
    "    seq = attrs.get(\"sequences\", None)\n",
    "    if seq is not None:\n",
    "        print(node, seq[:50])   # nur die ersten 50 Stellen\n",
    "\"\"\"\n",
    "\n",
    "data_sample = random.choice(data)\n",
    "#example = load_file(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a98fc9ba-1f51-41b7-b406-8fa6fadbc1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0.3359,   64.6942, -286.8312,   59.1449,   78.5914,   -0.4072,\n",
       "         109.2890,  115.3089,   65.5804], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, DirGNNConv\n",
    "import numpy as np\n",
    "\n",
    "class RecipientFinder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, dropout=0.3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.graph_convolution = DirGNNConv(GCNConv(in_channels, hidden_channels), alpha = 1) # Alpha = 1 is correct!\n",
    "        self.lin = nn.Linear(in_channels + hidden_channels, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        x_in = x\n",
    "        x = self.graph_convolution(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = torch.cat([x_in, x], dim=1)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x.view(-1)\n",
    "\n",
    "i = 3\n",
    "model = RecipientFinder(in_channels=4, hidden_channels=4)\n",
    "model(data[i].x, data[i].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2d9481c-667e-461a-ad7e-36cb8de7e17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2884/535982600.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Weight: 5.72\n",
      "Epoch 01 | Loss: 1.1931 | Acc: 0.931 | Prec: 0.225 | Rec: 0.553 | F1: 0.320\n",
      "Epoch 02 | Loss: 0.3720 | Acc: 0.941 | Prec: 0.278 | Rec: 0.639 | F1: 0.387\n",
      "Epoch 03 | Loss: 0.2943 | Acc: 0.933 | Prec: 0.266 | Rec: 0.721 | F1: 0.388\n",
      "Epoch 04 | Loss: 0.2682 | Acc: 0.953 | Prec: 0.294 | Rec: 0.433 | F1: 0.350\n",
      "Epoch 05 | Loss: 0.2609 | Acc: 0.935 | Prec: 0.264 | Rec: 0.667 | F1: 0.378\n",
      "Epoch 06 | Loss: 0.2516 | Acc: 0.953 | Prec: 0.314 | Rec: 0.509 | F1: 0.388\n",
      "Epoch 07 | Loss: 0.2426 | Acc: 0.949 | Prec: 0.303 | Rec: 0.565 | F1: 0.394\n",
      "Epoch 08 | Loss: 0.2375 | Acc: 0.947 | Prec: 0.302 | Rec: 0.611 | F1: 0.404\n",
      "Epoch 09 | Loss: 0.2303 | Acc: 0.962 | Prec: 0.369 | Rec: 0.390 | F1: 0.379\n",
      "Epoch 10 | Loss: 0.2297 | Acc: 0.950 | Prec: 0.320 | Rec: 0.611 | F1: 0.420\n",
      "Epoch 11 | Loss: 0.2355 | Acc: 0.957 | Prec: 0.331 | Rec: 0.446 | F1: 0.380\n",
      "Epoch 12 | Loss: 0.2192 | Acc: 0.966 | Prec: 0.375 | Rec: 0.224 | F1: 0.280\n",
      "Epoch 13 | Loss: 0.2307 | Acc: 0.967 | Prec: 0.412 | Rec: 0.311 | F1: 0.355\n",
      "Epoch 14 | Loss: 0.2184 | Acc: 0.957 | Prec: 0.362 | Rec: 0.622 | F1: 0.458\n",
      "Epoch 15 | Loss: 0.2229 | Acc: 0.938 | Prec: 0.291 | Rec: 0.769 | F1: 0.422\n",
      "Epoch 16 | Loss: 0.2255 | Acc: 0.960 | Prec: 0.339 | Rec: 0.389 | F1: 0.362\n",
      "Epoch 17 | Loss: 0.2187 | Acc: 0.967 | Prec: 0.377 | Rec: 0.198 | F1: 0.260\n",
      "Epoch 18 | Loss: 0.2313 | Acc: 0.953 | Prec: 0.340 | Rec: 0.649 | F1: 0.446\n",
      "Epoch 19 | Loss: 0.2173 | Acc: 0.921 | Prec: 0.254 | Rec: 0.863 | F1: 0.392\n",
      "Epoch 20 | Loss: 0.2244 | Acc: 0.963 | Prec: 0.348 | Rec: 0.308 | F1: 0.327\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# === 1. Modell, Optimizer, Loss ===\n",
    "model = RecipientFinder(in_channels=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Klassengewichte berechnen (gegen Ungleichgewicht)\n",
    "all_labels = torch.cat([g.y for g in data])\n",
    "ratio = (len(all_labels) - all_labels.sum()) / all_labels.sum()\n",
    "pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "print(f\"Pos Weight: {pos_weight.item():.2f}\")\n",
    "\n",
    "# === 2. Training & Evaluation ===\n",
    "\n",
    "# Train/Test Split\n",
    "random.shuffle(data)\n",
    "split_idx = int(0.5 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "test_data = data[split_idx:]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(train_data, batch_size=8)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(out, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        preds = torch.sigmoid(out) > 0.5\n",
    "        total_correct += (preds == batch.y.bool()).sum().item()\n",
    "        total_nodes += batch.y.size(0)\n",
    "\n",
    "        # Metriken für Klasse 1\n",
    "        tp += ((preds == 1) & (batch.y == 1)).sum().item()\n",
    "        fp += ((preds == 1) & (batch.y == 0)).sum().item()\n",
    "        fn += ((preds == 0) & (batch.y == 1)).sum().item()\n",
    "\n",
    "    acc = total_correct / total_nodes\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "# === 3. Training starten ===\n",
    "for epoch in range(1, 21):\n",
    "    loss = train()\n",
    "    acc, prec, rec, f1 = evaluate(test_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Acc: {acc:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5dee38d2-5ae4-4e97-8df9-eb780ee12163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecipientFinder(\n",
      "  (fusion_layers): ModuleList(\n",
      "    (0-1): 2 x ParentChildFusionLayer()\n",
      "  )\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=16, bias=True)\n",
      "    (1): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3.4515e-02, 2.6299e-02, 5.3271e-02, 4.7402e-02, 6.4433e+00, 7.7521e-02,\n",
       "        3.1081e+00, 1.4092e+01, 2.9121e+01], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "\n",
    "class ParentChildFusionLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    A MessagePassing layer designed for tree-like graphs where each parent\n",
    "    has either exactly two children or none. For each parent node i, the\n",
    "    features of the parent and its two children (if present) are concatenated\n",
    "    and passed through a fully connected layer.\n",
    "\n",
    "    This layer does not use any attention or permutation-invariant\n",
    "    aggregation: child messages are collected explicitly and concatenated\n",
    "    in a fixed order. The user must ensure that each parent node has either\n",
    "    (0 or 2) incoming edges, and that the edge_index ordering encodes a\n",
    "    consistent left/right child order.\n",
    "\n",
    "    Input dimensions:\n",
    "        - Node feature dimension: in_dim\n",
    "        - Output feature dimension: out_dim\n",
    "\n",
    "    Output:\n",
    "        - New node embeddings of dimension out_dim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim):\n",
    "        # We do not use built-in aggregation (\"add\", \"mean\", ...) because\n",
    "        # we aggregate manually. Set aggr=None.\n",
    "            \n",
    "        # Each node will produce: [parent_features, child1, child2]\n",
    "        # If a node has no children, child features are zero-padded.\n",
    "        super().__init__(node_dim=0, aggr=None)\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def aggregate(self, inputs, index, ptr=None, dim_size=None):\n",
    "        \"\"\"\n",
    "        Collect exactly two child feature vectors per parent.\n",
    "\n",
    "        inputs:  (num_edges, in_dim)\n",
    "        index:   (num_edges,) target node for each edge\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (num_nodes, 2 * in_dim) containing the two\n",
    "            children features for each parent. Order is determined by\n",
    "            edge ordering and should be consistent in the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # Determine number of nodes from dim_size (preferred), fall back to index\n",
    "        if dim_size is not None:\n",
    "            num_nodes = dim_size\n",
    "        else:\n",
    "            num_nodes = int(index.max().item()) + 1\n",
    "\n",
    "        device = inputs.device\n",
    "\n",
    "        # Preallocate storage\n",
    "        children = torch.zeros(num_nodes, 2, self.in_dim, device=device)\n",
    "\n",
    "        # Compute for each edge its \"child slot\" 0 or 1\n",
    "        # Example: for index = [3,3,5,5], this produces [0,1,0,1]\n",
    "        slot = torch.zeros_like(index)\n",
    "        slot[1:] = (index[1:] == index[:-1]).long()\n",
    "\n",
    "        # Vectorized scatter operation\n",
    "        children[index, slot] = inputs\n",
    "\n",
    "        return children.reshape(num_nodes, 2 * self.in_dim)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"\n",
    "        aggr_out: (num_nodes, 2*in_dim) concatenated children features\n",
    "        x:        (num_nodes, in_dim)   parent features\n",
    "\n",
    "        Returns:\n",
    "            Fused parent representation → out_dim\n",
    "        \"\"\"\n",
    "        fused = torch.cat([x, aggr_out], dim=-1)\n",
    "        return fused\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x: (num_nodes, in_dim)\n",
    "        edge_index: (2, num_edges), where edges point child -> parent\n",
    "\n",
    "        Returns:\n",
    "            Updated node embeddings (num_nodes, out_dim)\n",
    "        \"\"\"\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "\n",
    "class RecipientFinder(nn.Module):\n",
    "    \"\"\"\n",
    "    A model that stacks several ParentChildFusionLayers followed by\n",
    "    fully connected layers for prediction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Dimensionality of the input node features.\n",
    "    hidden_channels : int\n",
    "        Dimensionality after the ParentChildFusionLayers.\n",
    "    num_fusion_layers : int\n",
    "        Number of ParentChildFusionLayers to apply sequentially.\n",
    "    dropout : float\n",
    "        Dropout probability for the fully connected classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels = 16,\n",
    "                 num_fusion_layers=2, num_fc_layers = 2, dropout=0.3):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # ----- Fusion Layers -----\n",
    "        self.fusion_layers = nn.ModuleList()\n",
    "        current_dim = in_channels\n",
    "\n",
    "        for _ in range(num_fusion_layers):\n",
    "            self.fusion_layers.append(ParentChildFusionLayer(in_dim=current_dim))\n",
    "            current_dim = current_dim * 3 # 3 is coming from one parent and two children. If there are no children it is filled with zeros.\n",
    "\n",
    "        # ----- Fully Connected Layers -----\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # First FC layer: (current_dim → hidden_channels) OR directly → 1\n",
    "        if num_fc_layers == 1:\n",
    "            self.fc_layers.append(nn.Linear(current_dim, 1))\n",
    "        else:\n",
    "            # First hidden layer\n",
    "            self.fc_layers.append(nn.Linear(current_dim, hidden_channels))\n",
    "            # Middle hidden FC layers\n",
    "            for _ in range(num_fc_layers - 2):\n",
    "                self.fc_layers.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "            # Final output layer\n",
    "            self.fc_layers.append(nn.Linear(hidden_channels, 1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Apply stacked fusion layers followed by a linear classifier.\n",
    "        \"\"\"\n",
    "\n",
    "        # ----- ParentChildFusionLayers -----\n",
    "        for layer in self.fusion_layers:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        # ----- Fully Connected Layers -----\n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = layer(x)\n",
    "            if i < len(self.fc_layers) - 1:\n",
    "                x = F.relu(x)\n",
    "\n",
    "        return x.view(-1)\n",
    "\n",
    "\n",
    "i = 0\n",
    "model = RecipientFinder(in_channels = data[i].x.shape[1])\n",
    "print(model)\n",
    "model(data[i].x, data[i].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cbc002a-722d-447f-a0c9-dd2c7ee67742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[i].x.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
