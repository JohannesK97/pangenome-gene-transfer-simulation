{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06d82946-bd9d-4f34-bfb0-c50b36e61fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhewm\\AppData\\Local\\Temp\\ipykernel_11436\\406062616.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edges = torch.tensor(graph_properties[1], dtype=torch.long)  # [2, num_edges]\n",
      "C:\\Users\\uhewm\\AppData\\Local\\Temp\\ipykernel_11436\\406062616.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coords = torch.tensor(graph_properties[2].T)           # [2, num_nodes]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, DirGNNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import random, h5py, pickle, glob, os\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "\n",
    "output_dir = r\"C:\\Users\\uhewm\\Desktop\\ProjectHGT\\simulation_chunks(4)\"\n",
    "all_files = sorted(glob.glob(os.path.join(output_dir, \"*.h5\")))\n",
    "\n",
    "graphs = []\n",
    "graphs_modified = []\n",
    "\n",
    "for file in random.sample(all_files, 1000):\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        grp = f[\"results\"]\n",
    "        graph_properties = pickle.loads(grp[\"graph_properties\"][()])\n",
    "        \n",
    "        nodes = torch.tensor(graph_properties[0])              # [num_nodes]\n",
    "        edges = torch.tensor(graph_properties[1], dtype=torch.long)  # [2, num_edges]\n",
    "        coords = torch.tensor(graph_properties[2].T)           # [2, num_nodes]\n",
    "        #edges_reversed = edges.flip(0)  # Tauscht Zeile 0 und 1\n",
    "\n",
    "        x_node_features = coords.float().T\n",
    "        \n",
    "        # Erstelle einen gerichteten Graphen\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Füge Knoten hinzu (optional mit Koordinaten als Attribut)\n",
    "        for i, node_id in enumerate(nodes.tolist()):\n",
    "            G.add_node(node_id, core_distance = coords[:, i].tolist()[0], allele_distance = coords[:, i].tolist()[1])\n",
    "        \n",
    "        # Füge Kanten hinzu\n",
    "        edge_list = edges.tolist()\n",
    "        for src, dst in zip(edge_list[0], edge_list[1]):\n",
    "            G.add_edge(src, dst)\n",
    "\n",
    "        H = deepcopy(G)\n",
    "            \n",
    "        for node in G.nodes():\n",
    "            children = list(G.predecessors(node))\n",
    "            if children:\n",
    "                core_sum = sum(G.nodes[child]['core_distance'] for child in children)\n",
    "                allele_sum = sum(G.nodes[child]['allele_distance'] for child in children)\n",
    "                H.nodes[node]['core_distance'] = G.nodes[node]['core_distance'] - core_sum\n",
    "                H.nodes[node]['allele_distance'] = G.nodes[node]['allele_distance'] - allele_sum\n",
    "            else:\n",
    "                H.nodes[node]['core_distance'] = G.nodes[node]['core_distance']\n",
    "                H.nodes[node]['allele_distance'] = G.nodes[node]['allele_distance']\n",
    "\n",
    "\n",
    "        node_features = []\n",
    "        for node in list(H.nodes):\n",
    "            core = H.nodes[node].get(\"core_distance\", 0.0)\n",
    "            allele = H.nodes[node].get(\"allele_distance\", 0.0)\n",
    "            node_features.append([core, allele])\n",
    "        coords_modified = torch.tensor(node_features, dtype=torch.float32).T\n",
    "         \n",
    "        # Node features: nur die zwei Werte pro Knoten (coords)\n",
    "        x_node_features_modified = coords_modified.float().T  # Shape [num_nodes, 2]\n",
    "\n",
    "        # Labels\n",
    "        theta_gains = torch.tensor(\n",
    "            [1 if node in grp.attrs[\"parental_nodes_hgt_events_corrected\"] else 0 \n",
    "             for node in graph_properties[0]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # PyG-Graph erstellen\n",
    "        data = Data(\n",
    "            x=x_node_features,       # Node Features [num_nodes, 2]\n",
    "            edge_index=edges,        # Edge Index [2, num_edges]\n",
    "            y=theta_gains            # Labels [num_nodes]\n",
    "        )\n",
    "        graphs.append(data)\n",
    "\n",
    "        # PyG-Graph erstellen\n",
    "        data_modified = Data(\n",
    "            x=x_node_features_modified,       # Node Features [num_nodes, 2]\n",
    "            edge_index=edges,        # Edge Index [2, num_edges]\n",
    "            y=theta_gains            # Labels [num_nodes]\n",
    "        )\n",
    "        graphs_modified.append(data_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c33e9422-2691-4852-9ed5-9a28c8787df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = graphs_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b3e3e3e-a23c-4a32-a2ae-e716e60ba1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhewm\\AppData\\Local\\Temp\\ipykernel_11436\\91557288.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Weight: 7.02\n",
      "Epoch 01 | Loss: 0.6993 | Acc: 0.975 | Prec: 0.422 | Rec: 0.894 | F1: 0.574\n",
      "Epoch 02 | Loss: 0.3453 | Acc: 0.981 | Prec: 0.488 | Rec: 0.912 | F1: 0.636\n",
      "Epoch 03 | Loss: 0.1872 | Acc: 0.985 | Prec: 0.559 | Rec: 0.894 | F1: 0.688\n",
      "Epoch 04 | Loss: 0.1484 | Acc: 0.987 | Prec: 0.602 | Rec: 0.878 | F1: 0.715\n",
      "Epoch 05 | Loss: 0.1324 | Acc: 0.986 | Prec: 0.575 | Rec: 0.912 | F1: 0.705\n",
      "Epoch 06 | Loss: 0.1179 | Acc: 0.985 | Prec: 0.551 | Rec: 0.905 | F1: 0.685\n",
      "Epoch 07 | Loss: 0.1108 | Acc: 0.985 | Prec: 0.553 | Rec: 0.878 | F1: 0.678\n",
      "Epoch 08 | Loss: 0.1070 | Acc: 0.990 | Prec: 0.667 | Rec: 0.874 | F1: 0.756\n",
      "Epoch 09 | Loss: 0.1063 | Acc: 0.991 | Prec: 0.707 | Rec: 0.836 | F1: 0.766\n",
      "Epoch 10 | Loss: 0.1009 | Acc: 0.987 | Prec: 0.607 | Rec: 0.886 | F1: 0.721\n",
      "Epoch 11 | Loss: 0.0959 | Acc: 0.987 | Prec: 0.607 | Rec: 0.905 | F1: 0.727\n",
      "Epoch 12 | Loss: 0.0945 | Acc: 0.987 | Prec: 0.608 | Rec: 0.902 | F1: 0.727\n",
      "Epoch 13 | Loss: 0.0951 | Acc: 0.989 | Prec: 0.660 | Rec: 0.878 | F1: 0.753\n",
      "Epoch 14 | Loss: 0.0922 | Acc: 0.986 | Prec: 0.571 | Rec: 0.915 | F1: 0.703\n",
      "Epoch 15 | Loss: 0.0908 | Acc: 0.987 | Prec: 0.591 | Rec: 0.893 | F1: 0.711\n",
      "Epoch 16 | Loss: 0.0891 | Acc: 0.985 | Prec: 0.552 | Rec: 0.919 | F1: 0.690\n",
      "Epoch 17 | Loss: 0.0892 | Acc: 0.986 | Prec: 0.578 | Rec: 0.905 | F1: 0.706\n",
      "Epoch 18 | Loss: 0.0886 | Acc: 0.988 | Prec: 0.623 | Rec: 0.901 | F1: 0.737\n",
      "Epoch 19 | Loss: 0.0886 | Acc: 0.988 | Prec: 0.621 | Rec: 0.900 | F1: 0.735\n",
      "Epoch 20 | Loss: 0.0859 | Acc: 0.989 | Prec: 0.637 | Rec: 0.898 | F1: 0.745\n",
      "Epoch 21 | Loss: 0.0851 | Acc: 0.989 | Prec: 0.637 | Rec: 0.893 | F1: 0.744\n",
      "Epoch 22 | Loss: 0.0840 | Acc: 0.985 | Prec: 0.566 | Rec: 0.913 | F1: 0.699\n",
      "Epoch 23 | Loss: 0.0832 | Acc: 0.986 | Prec: 0.587 | Rec: 0.912 | F1: 0.714\n",
      "Epoch 24 | Loss: 0.0828 | Acc: 0.985 | Prec: 0.566 | Rec: 0.915 | F1: 0.700\n",
      "Epoch 25 | Loss: 0.0836 | Acc: 0.987 | Prec: 0.590 | Rec: 0.905 | F1: 0.714\n",
      "Epoch 26 | Loss: 0.0821 | Acc: 0.983 | Prec: 0.518 | Rec: 0.915 | F1: 0.662\n",
      "Epoch 27 | Loss: 0.0806 | Acc: 0.985 | Prec: 0.558 | Rec: 0.913 | F1: 0.692\n",
      "Epoch 28 | Loss: 0.0798 | Acc: 0.986 | Prec: 0.583 | Rec: 0.915 | F1: 0.712\n",
      "Epoch 29 | Loss: 0.0805 | Acc: 0.987 | Prec: 0.610 | Rec: 0.901 | F1: 0.727\n",
      "Epoch 30 | Loss: 0.0806 | Acc: 0.989 | Prec: 0.640 | Rec: 0.885 | F1: 0.743\n",
      "Epoch 31 | Loss: 0.0801 | Acc: 0.986 | Prec: 0.586 | Rec: 0.908 | F1: 0.712\n",
      "Epoch 32 | Loss: 0.0779 | Acc: 0.989 | Prec: 0.639 | Rec: 0.890 | F1: 0.744\n",
      "Epoch 33 | Loss: 0.0790 | Acc: 0.986 | Prec: 0.580 | Rec: 0.904 | F1: 0.706\n",
      "Epoch 34 | Loss: 0.0783 | Acc: 0.985 | Prec: 0.556 | Rec: 0.923 | F1: 0.694\n",
      "Epoch 35 | Loss: 0.0776 | Acc: 0.986 | Prec: 0.572 | Rec: 0.909 | F1: 0.702\n",
      "Epoch 36 | Loss: 0.0774 | Acc: 0.988 | Prec: 0.614 | Rec: 0.901 | F1: 0.730\n",
      "Epoch 37 | Loss: 0.0763 | Acc: 0.987 | Prec: 0.609 | Rec: 0.898 | F1: 0.726\n",
      "Epoch 38 | Loss: 0.0771 | Acc: 0.986 | Prec: 0.580 | Rec: 0.917 | F1: 0.711\n",
      "Epoch 39 | Loss: 0.0770 | Acc: 0.986 | Prec: 0.586 | Rec: 0.906 | F1: 0.712\n",
      "Epoch 40 | Loss: 0.0767 | Acc: 0.987 | Prec: 0.603 | Rec: 0.905 | F1: 0.724\n",
      "Epoch 41 | Loss: 0.0762 | Acc: 0.987 | Prec: 0.609 | Rec: 0.904 | F1: 0.727\n",
      "Epoch 42 | Loss: 0.0751 | Acc: 0.987 | Prec: 0.595 | Rec: 0.917 | F1: 0.722\n",
      "Epoch 43 | Loss: 0.0747 | Acc: 0.987 | Prec: 0.606 | Rec: 0.900 | F1: 0.724\n",
      "Epoch 44 | Loss: 0.0748 | Acc: 0.987 | Prec: 0.594 | Rec: 0.909 | F1: 0.718\n",
      "Epoch 45 | Loss: 0.0752 | Acc: 0.985 | Prec: 0.559 | Rec: 0.913 | F1: 0.693\n",
      "Epoch 46 | Loss: 0.0743 | Acc: 0.984 | Prec: 0.537 | Rec: 0.929 | F1: 0.681\n",
      "Epoch 47 | Loss: 0.0733 | Acc: 0.987 | Prec: 0.602 | Rec: 0.917 | F1: 0.727\n",
      "Epoch 48 | Loss: 0.0742 | Acc: 0.987 | Prec: 0.596 | Rec: 0.920 | F1: 0.723\n",
      "Epoch 49 | Loss: 0.0742 | Acc: 0.987 | Prec: 0.605 | Rec: 0.916 | F1: 0.729\n",
      "Epoch 50 | Loss: 0.0739 | Acc: 0.987 | Prec: 0.598 | Rec: 0.919 | F1: 0.724\n"
     ]
    }
   ],
   "source": [
    "#### FUNKTIONIERT!\n",
    "\n",
    "from torch_geometric.nn import GCNConv, DirGNNConv, GATConv\n",
    "\n",
    "graphs = graphs_modified\n",
    "\n",
    "# Train/Test Split\n",
    "random.shuffle(graphs)\n",
    "split_idx = int(0.8 * len(graphs))\n",
    "train_graphs = graphs[:split_idx]\n",
    "test_graphs = graphs[split_idx:]\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=8)\n",
    "\n",
    "\"\"\"\n",
    "# === 2. Modell definieren ===\n",
    "class GCNClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, dropout=0.3):\n",
    "        super().__init__()\n",
    "        # Innerer conv wird an DirGNNConv übergeben\n",
    "        self.conv1 = DirGNNConv(GCNConv(in_channels, hidden_channels))\n",
    "        self.conv2 = DirGNNConv(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return x.view(-1)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GCNClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = DirGNNConv(GCNConv(in_channels, hidden_channels), alpha = 0)\n",
    "        self.conv2 = DirGNNConv(GCNConv(hidden_channels, hidden_channels), alpha = 0)\n",
    "        self.lin = nn.Linear(hidden_channels, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #edge_index =  torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "\n",
    "# === 3. Modell, Optimizer, Loss ===\n",
    "model = GCNClassifier(in_channels=2, hidden_channels=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Klassengewichte berechnen (gegen Ungleichgewicht)\n",
    "all_labels = torch.cat([g.y for g in train_graphs])\n",
    "ratio = (len(all_labels) - all_labels.sum()) / all_labels.sum()\n",
    "pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "print(f\"Pos Weight: {pos_weight.item():.2f}\")\n",
    "\n",
    "# === 4. Training & Evaluation ===\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(out, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        preds = torch.sigmoid(out) > 0.5\n",
    "        total_correct += (preds == batch.y.bool()).sum().item()\n",
    "        total_nodes += batch.y.size(0)\n",
    "\n",
    "        # Metriken für Klasse 1\n",
    "        tp += ((preds == 1) & (batch.y == 1)).sum().item()\n",
    "        fp += ((preds == 1) & (batch.y == 0)).sum().item()\n",
    "        fn += ((preds == 0) & (batch.y == 1)).sum().item()\n",
    "\n",
    "    acc = total_correct / total_nodes\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "# === 5. Training starten ===\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    acc, prec, rec, f1 = evaluate(test_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Acc: {acc:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4758b855-265b-4b64-801f-f275f7528c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Weight: 7.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhewm\\AppData\\Local\\Temp\\ipykernel_11436\\3901431779.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.3385 | Acc: 0.984 | Prec: 0.540 | Rec: 0.818 | F1: 0.651\n",
      "Epoch 02 | Loss: 0.1416 | Acc: 0.977 | Prec: 0.444 | Rec: 0.904 | F1: 0.595\n",
      "Epoch 03 | Loss: 0.1263 | Acc: 0.980 | Prec: 0.478 | Rec: 0.915 | F1: 0.628\n",
      "Epoch 04 | Loss: 0.1151 | Acc: 0.980 | Prec: 0.476 | Rec: 0.917 | F1: 0.627\n",
      "Epoch 05 | Loss: 0.1093 | Acc: 0.983 | Prec: 0.530 | Rec: 0.902 | F1: 0.668\n",
      "Epoch 06 | Loss: 0.1050 | Acc: 0.986 | Prec: 0.582 | Rec: 0.874 | F1: 0.698\n",
      "Epoch 07 | Loss: 0.0992 | Acc: 0.981 | Prec: 0.499 | Rec: 0.912 | F1: 0.645\n",
      "Epoch 08 | Loss: 0.0964 | Acc: 0.984 | Prec: 0.539 | Rec: 0.902 | F1: 0.675\n",
      "Epoch 09 | Loss: 0.0984 | Acc: 0.984 | Prec: 0.549 | Rec: 0.901 | F1: 0.682\n",
      "Epoch 10 | Loss: 0.0938 | Acc: 0.986 | Prec: 0.590 | Rec: 0.887 | F1: 0.709\n",
      "Epoch 11 | Loss: 0.0928 | Acc: 0.987 | Prec: 0.593 | Rec: 0.886 | F1: 0.710\n",
      "Epoch 12 | Loss: 0.0919 | Acc: 0.986 | Prec: 0.587 | Rec: 0.894 | F1: 0.709\n",
      "Epoch 13 | Loss: 0.0914 | Acc: 0.982 | Prec: 0.502 | Rec: 0.920 | F1: 0.650\n",
      "Epoch 14 | Loss: 0.0920 | Acc: 0.983 | Prec: 0.528 | Rec: 0.909 | F1: 0.668\n",
      "Epoch 15 | Loss: 0.0885 | Acc: 0.987 | Prec: 0.590 | Rec: 0.900 | F1: 0.713\n",
      "Epoch 16 | Loss: 0.0881 | Acc: 0.983 | Prec: 0.527 | Rec: 0.910 | F1: 0.668\n",
      "Epoch 17 | Loss: 0.0886 | Acc: 0.987 | Prec: 0.600 | Rec: 0.894 | F1: 0.718\n",
      "Epoch 18 | Loss: 0.0868 | Acc: 0.988 | Prec: 0.620 | Rec: 0.887 | F1: 0.730\n",
      "Epoch 19 | Loss: 0.0879 | Acc: 0.986 | Prec: 0.581 | Rec: 0.908 | F1: 0.708\n",
      "Epoch 20 | Loss: 0.0871 | Acc: 0.984 | Prec: 0.549 | Rec: 0.910 | F1: 0.685\n",
      "Epoch 21 | Loss: 0.0872 | Acc: 0.987 | Prec: 0.592 | Rec: 0.908 | F1: 0.716\n",
      "Epoch 22 | Loss: 0.0854 | Acc: 0.988 | Prec: 0.626 | Rec: 0.900 | F1: 0.738\n",
      "Epoch 23 | Loss: 0.0855 | Acc: 0.988 | Prec: 0.613 | Rec: 0.894 | F1: 0.727\n",
      "Epoch 24 | Loss: 0.0855 | Acc: 0.988 | Prec: 0.623 | Rec: 0.897 | F1: 0.735\n",
      "Epoch 25 | Loss: 0.0842 | Acc: 0.987 | Prec: 0.594 | Rec: 0.902 | F1: 0.716\n",
      "Epoch 26 | Loss: 0.0835 | Acc: 0.988 | Prec: 0.612 | Rec: 0.902 | F1: 0.730\n",
      "Epoch 27 | Loss: 0.0834 | Acc: 0.987 | Prec: 0.591 | Rec: 0.904 | F1: 0.715\n",
      "Epoch 28 | Loss: 0.0842 | Acc: 0.989 | Prec: 0.653 | Rec: 0.887 | F1: 0.753\n",
      "Epoch 29 | Loss: 0.0825 | Acc: 0.987 | Prec: 0.598 | Rec: 0.915 | F1: 0.723\n",
      "Epoch 30 | Loss: 0.0828 | Acc: 0.987 | Prec: 0.601 | Rec: 0.908 | F1: 0.723\n",
      "Epoch 31 | Loss: 0.0834 | Acc: 0.988 | Prec: 0.610 | Rec: 0.913 | F1: 0.731\n",
      "Epoch 32 | Loss: 0.0824 | Acc: 0.987 | Prec: 0.608 | Rec: 0.905 | F1: 0.727\n",
      "Epoch 33 | Loss: 0.0839 | Acc: 0.987 | Prec: 0.600 | Rec: 0.913 | F1: 0.724\n",
      "Epoch 34 | Loss: 0.0824 | Acc: 0.988 | Prec: 0.622 | Rec: 0.898 | F1: 0.735\n",
      "Epoch 35 | Loss: 0.0814 | Acc: 0.987 | Prec: 0.602 | Rec: 0.913 | F1: 0.726\n",
      "Epoch 36 | Loss: 0.0800 | Acc: 0.988 | Prec: 0.622 | Rec: 0.909 | F1: 0.739\n",
      "Epoch 37 | Loss: 0.0824 | Acc: 0.987 | Prec: 0.602 | Rec: 0.909 | F1: 0.724\n",
      "Epoch 38 | Loss: 0.0810 | Acc: 0.986 | Prec: 0.583 | Rec: 0.915 | F1: 0.712\n",
      "Epoch 39 | Loss: 0.0817 | Acc: 0.988 | Prec: 0.617 | Rec: 0.908 | F1: 0.735\n",
      "Epoch 40 | Loss: 0.0801 | Acc: 0.987 | Prec: 0.596 | Rec: 0.915 | F1: 0.722\n",
      "Epoch 41 | Loss: 0.0803 | Acc: 0.987 | Prec: 0.609 | Rec: 0.905 | F1: 0.728\n",
      "Epoch 42 | Loss: 0.0805 | Acc: 0.988 | Prec: 0.612 | Rec: 0.906 | F1: 0.730\n",
      "Epoch 43 | Loss: 0.0801 | Acc: 0.987 | Prec: 0.607 | Rec: 0.910 | F1: 0.729\n",
      "Epoch 44 | Loss: 0.0805 | Acc: 0.987 | Prec: 0.595 | Rec: 0.915 | F1: 0.721\n",
      "Epoch 45 | Loss: 0.0805 | Acc: 0.988 | Prec: 0.627 | Rec: 0.900 | F1: 0.739\n",
      "Epoch 46 | Loss: 0.0797 | Acc: 0.986 | Prec: 0.583 | Rec: 0.919 | F1: 0.713\n",
      "Epoch 47 | Loss: 0.0796 | Acc: 0.988 | Prec: 0.623 | Rec: 0.908 | F1: 0.739\n",
      "Epoch 48 | Loss: 0.0800 | Acc: 0.986 | Prec: 0.581 | Rec: 0.920 | F1: 0.712\n",
      "Epoch 49 | Loss: 0.0804 | Acc: 0.987 | Prec: 0.589 | Rec: 0.917 | F1: 0.718\n",
      "Epoch 50 | Loss: 0.0793 | Acc: 0.988 | Prec: 0.610 | Rec: 0.912 | F1: 0.731\n",
      "\n",
      "Bester Threshold: 0.750 mit F1-Score: 0.794\n",
      "Evaluation mit bestem Threshold:\n",
      "Acc: 0.992 | Prec: 0.756 | Rec: 0.834 | F1: 0.794\n",
      "\n",
      "Ein paar Beispielvorhersagen auf Trainingsdaten mit bestem Threshold:\n",
      "Sample 1:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.2352\n",
      "  Predicted label: 0\n",
      "Sample 2:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0035\n",
      "  Predicted label: 0\n",
      "Sample 3:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "# === 2. Modell definieren ===\n",
    "class GCNClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = DirGNNConv(GCNConv(in_channels, hidden_channels), alpha = 0)\n",
    "        self.conv2 = DirGNNConv(GCNConv(hidden_channels, hidden_channels), alpha = 0)\n",
    "        self.conv3 = DirGNNConv(GCNConv(hidden_channels, hidden_channels), alpha = 0)\n",
    "        self.conv4 = DirGNNConv(GCNConv(hidden_channels, hidden_channels), alpha = 0)\n",
    "        self.conv5 = DirGNNConv(GCNConv(hidden_channels, hidden_channels), alpha = 0)\n",
    "        self.lin = nn.Linear(hidden_channels, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #edge_index = edge_index[[1, 0], :]\n",
    "        edge_index, _ = add_self_loops(edge_index)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.lin(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "\n",
    "# === 3. Modell, Optimizer, Loss ===\n",
    "model = GCNClassifier(in_channels=2, hidden_channels=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Klassengewichte berechnen (gegen Ungleichgewicht)\n",
    "all_labels = torch.cat([g.y for g in train_graphs])\n",
    "ratio = (len(all_labels) - all_labels.sum()) / all_labels.sum()\n",
    "pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "print(f\"Pos Weight: {pos_weight.item():.2f}\")\n",
    "\n",
    "# === 4. Training & Evaluation ===\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(out, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        preds = torch.sigmoid(out) > threshold\n",
    "        total_correct += (preds == batch.y.bool()).sum().item()\n",
    "        total_nodes += batch.y.size(0)\n",
    "\n",
    "        tp += ((preds == 1) & (batch.y == 1)).sum().item()\n",
    "        fp += ((preds == 1) & (batch.y == 0)).sum().item()\n",
    "        fn += ((preds == 0) & (batch.y == 1)).sum().item()\n",
    "\n",
    "    acc = total_correct / total_nodes\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_best_threshold(loader, thresholds=np.linspace(0, 1, 101)):\n",
    "    model.eval()\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    # Alle Outputs und Labels sammeln, damit man nicht für jeden Threshold neu durch die Daten geht\n",
    "    all_outs = []\n",
    "    all_labels = []\n",
    "    for batch in loader:\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        all_outs.append(torch.sigmoid(out))\n",
    "        all_labels.append(batch.y)\n",
    "    all_outs = torch.cat(all_outs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        preds = all_outs > threshold\n",
    "        tp = ((preds == 1) & (all_labels == 1)).sum().item()\n",
    "        fp = ((preds == 1) & (all_labels == 0)).sum().item()\n",
    "        fn = ((preds == 0) & (all_labels == 1)).sum().item()\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-8)\n",
    "        recall = tp / (tp + fn + 1e-8)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def show_some_predictions(loader, n_samples=3, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in loader:\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        probs = torch.sigmoid(out)\n",
    "        preds = (probs > threshold).long()\n",
    "        all_probs.append(probs)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(batch.y)\n",
    "\n",
    "    all_probs = torch.cat(all_probs)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    total_samples = len(all_labels)\n",
    "    indices = random.sample(range(total_samples), k=min(n_samples, total_samples))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        print(f\"Sample {i + 1}:\")\n",
    "        print(f\"  True label:      {all_labels[idx].item()}\")\n",
    "        print(f\"  Predicted prob:  {all_probs[idx].item():.4f}\")\n",
    "        print(f\"  Predicted label: {all_preds[idx].item()}\")\n",
    "\n",
    "# === 5. Training starten ===\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    acc, prec, rec, f1 = evaluate(test_loader, threshold=0.5)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Acc: {acc:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}\")\n",
    "\n",
    "# Nach Training besten Threshold bestimmen\n",
    "best_threshold, best_f1 = find_best_threshold(test_loader)\n",
    "print(f\"\\nBester Threshold: {best_threshold:.3f} mit F1-Score: {best_f1:.3f}\")\n",
    "\n",
    "# Evaluation mit bestem Threshold\n",
    "acc, prec, rec, f1 = evaluate(test_loader, threshold=best_threshold)\n",
    "print(f\"Evaluation mit bestem Threshold:\")\n",
    "print(f\"Acc: {acc:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}\")\n",
    "\n",
    "print(\"\\nEin paar Beispielvorhersagen auf Trainingsdaten mit bestem Threshold:\")\n",
    "show_some_predictions(train_loader, n_samples=3, threshold=best_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5554bc2-ba45-409b-8bd2-a7e0d483165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ein paar Beispielvorhersagen auf Trainingsdaten mit bestem Threshold:\n",
      "Sample 1:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0040\n",
      "  Predicted label: 0\n",
      "Sample 2:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0221\n",
      "  Predicted label: 0\n",
      "Sample 3:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0034\n",
      "  Predicted label: 0\n",
      "Sample 4:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 5:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0035\n",
      "  Predicted label: 0\n",
      "Sample 6:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0034\n",
      "  Predicted label: 0\n",
      "Sample 7:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 8:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 9:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 10:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 11:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0035\n",
      "  Predicted label: 0\n",
      "Sample 12:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0031\n",
      "  Predicted label: 0\n",
      "Sample 13:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 14:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0035\n",
      "  Predicted label: 0\n",
      "Sample 15:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 16:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0056\n",
      "  Predicted label: 0\n",
      "Sample 17:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0070\n",
      "  Predicted label: 0\n",
      "Sample 18:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0035\n",
      "  Predicted label: 0\n",
      "Sample 19:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 20:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0037\n",
      "  Predicted label: 0\n",
      "Sample 21:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0035\n",
      "  Predicted label: 0\n",
      "Sample 22:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 23:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0033\n",
      "  Predicted label: 0\n",
      "Sample 24:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0038\n",
      "  Predicted label: 0\n",
      "Sample 25:\n",
      "  True label:      0\n",
      "  Predicted prob:  0.0113\n",
      "  Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEin paar Beispielvorhersagen auf Trainingsdaten mit bestem Threshold:\")\n",
    "show_some_predictions(train_loader, n_samples=25, threshold=best_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04488c51-7bb7-4c04-b722-d31584fe58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhewm\\AppData\\Local\\Temp\\ipykernel_11436\\1236246542.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edges = torch.tensor(graph_properties[1])          # Shape [2, 198]\n",
      "C:\\Users\\uhewm\\AppData\\Local\\Temp\\ipykernel_11436\\1236246542.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coords = torch.tensor(graph_properties[2].T)       # Shape [2, 199]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 67\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [num_nodes]\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(logits)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Werte zwischen 0 und 1\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Map von Node-ID zu Wahrscheinlichkeit\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-hgt-sim\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-hgt-sim\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[61], line 18\u001b[0m, in \u001b[0;36mGCNClassifier.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#edge_index = edge_index[[1, 0], :]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     edge_index, _ \u001b[38;5;241m=\u001b[39m \u001b[43madd_self_loops\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-hgt-sim\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:459\u001b[0m, in \u001b[0;36madd_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    457\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_num_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m     size \u001b[38;5;241m=\u001b[39m (N, N)\n\u001b[0;32m    462\u001b[0m device \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-hgt-sim\\Lib\\site-packages\\torch_geometric\\utils\\num_nodes.py:36\u001b[0m, in \u001b[0;36mmaybe_num_nodes\u001b[1;34m(edge_index, num_nodes)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(edge_index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mint\u001b[39m(edge_index[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_index[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28mint\u001b[39m(edge_index[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for file in random.sample(all_files, 1):\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        grp = f[\"results\"]\n",
    "        graph_properties = pickle.loads(grp[\"graph_properties\"][()])\n",
    "        # Tensors erstellen\n",
    "        nodes = torch.tensor(graph_properties[0])          # Shape [199]\n",
    "        edges = torch.tensor(graph_properties[1])          # Shape [2, 198]\n",
    "        coords = torch.tensor(graph_properties[2].T)       # Shape [2, 199]\n",
    "        parental_nodes_hgt_events_corrected = grp.attrs[\"parental_nodes_hgt_events_corrected\"]\n",
    "        gene_absence_presence_matrix = grp.attrs[\"gene_absence_presence_matrix\"] \n",
    "\n",
    "        x_node_features = coords.float().T\n",
    "        \n",
    "        # Erstelle einen gerichteten Graphen\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Füge Knoten hinzu (optional mit Koordinaten als Attribut)\n",
    "        for i, node_id in enumerate(nodes.tolist()):\n",
    "            G.add_node(node_id, core_distance = coords[:, i].tolist()[0], allele_distance = coords[:, i].tolist()[1])\n",
    "        \n",
    "        # Füge Kanten hinzu\n",
    "        edge_list = edges.tolist()\n",
    "        for src, dst in zip(edge_list[0], edge_list[1]):\n",
    "            G.add_edge(src, dst)\n",
    "\n",
    "        H = deepcopy(G)\n",
    "            \n",
    "        for node in G.nodes():\n",
    "            children = list(G.predecessors(node))\n",
    "            if children:\n",
    "                core_sum = sum(G.nodes[child]['core_distance'] for child in children)\n",
    "                allele_sum = sum(G.nodes[child]['allele_distance'] for child in children)\n",
    "                H.nodes[node]['core_distance'] = G.nodes[node]['core_distance'] - core_sum\n",
    "                H.nodes[node]['allele_distance'] = G.nodes[node]['allele_distance'] - allele_sum\n",
    "            else:\n",
    "                H.nodes[node]['core_distance'] = G.nodes[node]['core_distance']\n",
    "                H.nodes[node]['allele_distance'] = G.nodes[node]['allele_distance']\n",
    "\n",
    "\n",
    "        node_features = []\n",
    "        for node in list(H.nodes):\n",
    "            core = H.nodes[node].get(\"core_distance\", 0.0)\n",
    "            allele = H.nodes[node].get(\"allele_distance\", 0.0)\n",
    "            node_features.append([core, allele])\n",
    "        coords_modified = torch.tensor(node_features, dtype=torch.float32).T\n",
    "         \n",
    "        # Node features: nur die zwei Werte pro Knoten (coords)\n",
    "        x_node_features_modified = coords_modified.float().T  # Shape [num_nodes, 2]\n",
    "\n",
    "        # Labels\n",
    "        theta_gains = torch.tensor(\n",
    "            [1 if node in grp.attrs[\"parental_nodes_hgt_events_corrected\"] else 0 \n",
    "             for node in graph_properties[0]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        x=x_node_features,       # Node Features [num_nodes, 2]\n",
    "        edge_index=edges,        # Edge Index [2, num_edges]\n",
    "        y=theta_gains            # Labels [num_nodes]\n",
    "\n",
    "\n",
    "# === 1. Modellvorhersagen berechnen ===\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(x, edge_index)  # Shape: [num_nodes]\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()  # Werte zwischen 0 und 1\n",
    "\n",
    "# Map von Node-ID zu Wahrscheinlichkeit\n",
    "pred_probs = {i: p for i, p in enumerate(probs)}\n",
    "\n",
    "# === 2. Visualisierung mit Vorhersagen ===\n",
    "from pyvis.network import Network\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "\n",
    "net = Network(height=\"900px\", width=\"100%\", directed=True)\n",
    "net.set_options(\"\"\"\n",
    "{\n",
    "    \"layout\": {\n",
    "      \"hierarchical\": {\n",
    "        \"enabled\": true,\n",
    "        \"direction\": \"DU\",\n",
    "        \"sortMethod\": \"directed\",\n",
    "        \"levelSeparation\": 50,\n",
    "        \"nodeSpacing\": 200\n",
    "      }\n",
    "    },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 12,\n",
    "    \"font\": { \"size\": 16 }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"arrows\": {\n",
    "      \"to\": { \"enabled\": true, \"scaleFactor\": 0.5 }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "G = H  # Graph mit berechneten core/allele Werten\n",
    "\n",
    "levels = defaultdict(list)\n",
    "for n in G.nodes:\n",
    "    level = G.nodes[n].get(\"level\", 0)\n",
    "    levels[level].append(int(n))\n",
    "\n",
    "def descendants_count(node):\n",
    "    return len(nx.descendants(G, node))\n",
    "\n",
    "for level in sorted(levels.keys()):\n",
    "    nodes_in_level = levels[level]\n",
    "    if level == 0:\n",
    "        leaves_level_0 = [n for n in nodes_in_level if n < 100]\n",
    "        nodes_sorted = sorted(leaves_level_0)\n",
    "    else:\n",
    "        nodes_sorted = nodes_in_level\n",
    "        \n",
    "    for n in nodes_sorted:\n",
    "        core = G.nodes[n].get('core_distance', 0)\n",
    "        allele = G.nodes[n].get('allele_distance', 0)\n",
    "        pred = pred_probs.get(n, None)\n",
    "\n",
    "        # Tooltip mit NN-Wahrscheinlichkeit\n",
    "        if pred is not None:\n",
    "            title = f\"Core: {core:.2f}, Allele: {allele:.2f}, NN: {pred:.3f}\"\n",
    "            label = f\"{n}\\n({core:.2f}, {allele:.2f}, p={pred:.2f})\"\n",
    "        else:\n",
    "            title = f\"Core: {core:.2f}, Allele: {allele:.2f}\"\n",
    "            label = f\"{n}\\n({core:.2f}, {allele:.2f})\"\n",
    "\n",
    "        color = \"lightblue\"\n",
    "        if n in parental_nodes_hgt_events_corrected:\n",
    "            color = \"red\"\n",
    "        elif n < 100 and gene_absence_presence_matrix[n] == 1:\n",
    "            color = \"green\"\n",
    "        elif n < 100 and gene_absence_presence_matrix[n] == 0:\n",
    "            color = \"black\"\n",
    "\n",
    "        net.add_node(n, label=label, title=title, color=color, level=level)\n",
    "\n",
    "# Edges hinzufügen\n",
    "for u, v in G.edges:\n",
    "    net.add_edge(u, v)\n",
    "\n",
    "net.show(\"graph_with_predictions.html\", notebook=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "828fdf22-53da-4f66-b35f-149d21e82f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [7.4939e-03, 0.0000e+00],\n",
       "        [5.7134e-02, 0.0000e+00],\n",
       "        [6.8664e-02, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.2620e-01, 0.0000e+00],\n",
       "        [1.6943e-01, 0.0000e+00],\n",
       "        [2.1331e-01, 0.0000e+00],\n",
       "        [2.2478e-01, 1.0000e+00],\n",
       "        [2.2977e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [3.4006e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [4.2579e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [5.0517e-01, 1.0000e+00],\n",
       "        [6.2606e-01, 0.0000e+00],\n",
       "        [4.8868e-01, 0.0000e+00],\n",
       "        [5.4694e-01, 0.0000e+00],\n",
       "        [6.4136e-01, 0.0000e+00],\n",
       "        [6.9294e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.2177e+00, 2.0000e+00],\n",
       "        [1.1704e+00, 1.0000e+00],\n",
       "        [1.1320e+00, 0.0000e+00],\n",
       "        [1.3392e+00, 0.0000e+00],\n",
       "        [1.2860e+00, 3.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.0041e+00, 2.0000e+00],\n",
       "        [1.0159e+00, 1.0000e+00],\n",
       "        [9.8636e-01, 0.0000e+00],\n",
       "        [2.0094e+00, 2.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [9.0421e-01, 1.0000e+00],\n",
       "        [1.6934e+00, 5.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.6465e+00, 3.0000e+00],\n",
       "        [1.7307e+00, 2.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.3752e+00, 2.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [2.0216e+00, 1.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [3.0458e+00, 6.0000e+00],\n",
       "        [2.1597e+00, 2.0000e+00],\n",
       "        [2.7809e+00, 4.0000e+00],\n",
       "        [3.1359e+00, 6.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.0747e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.5705e+00, 1.0000e+00],\n",
       "        [3.1662e+00, 4.0000e+00],\n",
       "        [2.0960e+00, 2.0000e+00],\n",
       "        [3.5335e+00, 6.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [2.9111e+00, 2.0000e+00],\n",
       "        [2.4433e+00, 2.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [3.1027e+00, 4.0000e+00],\n",
       "        [4.2269e+00, 5.0000e+00],\n",
       "        [2.0882e+00, 2.0000e+00],\n",
       "        [1.8229e+00, 0.0000e+00],\n",
       "        [3.8364e+00, 6.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [3.5247e+00, 2.0000e+00],\n",
       "        [1.2846e+01, 1.5000e+01],\n",
       "        [7.8186e+00, 5.0000e+00],\n",
       "        [5.7289e+00, 7.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [7.6798e+00, 5.0000e+00],\n",
       "        [5.7373e+00, 3.0000e+00],\n",
       "        [3.6498e+00, 2.0000e+00],\n",
       "        [8.6410e+00, 1.2000e+01],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [7.3610e+00, 1.3000e+01],\n",
       "        [5.6667e+00, 4.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [7.3359e+00, 1.2000e+01],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [4.5687e+00, 7.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [2.8113e+02, 2.0000e+01],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [2.5652e+01, 2.4000e+01],\n",
       "        [3.0809e+01, 2.8000e+01],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.2221e+01, 1.0000e+01],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.1869e+01, 8.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [1.1771e+01, 1.4000e+01],\n",
       "        [1.0566e+01, 1.4000e+01],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = graphs_modified[random.choice(range(len(graphs_modified)))]\n",
    "\n",
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c46f2-fe05-4453-8d4c-df2ade5ac248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangenome-gene-transfer-simulation",
   "language": "python",
   "name": "pangenome-gene-transfer-simulation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
