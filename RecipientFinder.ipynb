{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5e3cf2-68e9-4b46-9902-a208154da2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kippnich/miniconda3/envs/pangenome-hgt-sim/lib/python3.12/site-packages/numpy/core/getlimits.py:542: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n",
      "/mnt/c/Users/uhewm/OneDrive/PhD/Project No.2/pangenome-gene-transfer-simulation/DataLoader.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edges = torch.tensor(graph_properties[1], dtype=torch.long)  # [2, num_edges]\n",
      "/mnt/c/Users/uhewm/OneDrive/PhD/Project No.2/pangenome-gene-transfer-simulation/DataLoader.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coords = torch.tensor(graph_properties[2].T)             # [2, num_nodes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_163730.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_191463.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_27197.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_80205.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_158726.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_195334.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_99584.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_170527.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_37750.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_167108.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_198782.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_156999.h5: cannot reshape array of size 0 into shape (0,newaxis)\n",
      "Fehler beim Laden von /mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)/simulation_175065.h5: cannot reshape array of size 0 into shape (0,newaxis)\n"
     ]
    }
   ],
   "source": [
    "import DataLoader\n",
    "from importlib import reload\n",
    "reload(DataLoader)\n",
    "import os\n",
    "import random\n",
    "\n",
    "folder = \"/mnt/c/Users/uhewm/Desktop/ProjectHGT/simulation_chunks(5)\"\n",
    "\n",
    "files = [entry.path for entry in os.scandir(folder) if entry.is_file()]\n",
    "\n",
    "if len(files) > 10000:\n",
    "    files = random.sample(files, 10000)\n",
    "\n",
    "data_graphs = []\n",
    "for f in files:\n",
    "    try:\n",
    "        d = DataLoader.load_file(f)\n",
    "        DataLoader.aggregate_sequences(d)\n",
    "        data_graphs.append(d)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden von {f}: {e}\")\n",
    "\n",
    "data = []\n",
    "for G in data_graphs:\n",
    "    try:\n",
    "        dat = DataLoader.graph_to_dataset(G)\n",
    "        data.append(dat)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden von {G}: {e}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for node, attrs in data_graphs[0].nodes(data=True):\n",
    "    seq = attrs.get(\"sequences\", None)\n",
    "    if seq is not None:\n",
    "        print(node, seq[:50])   # nur die ersten 50 Stellen\n",
    "\"\"\"\n",
    "\n",
    "data_sample = random.choice(data)\n",
    "#example = load_file(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d51512-8591-4809-81f8-b8025818c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecipientFinder(\n",
      "  (fusion_layers): ModuleList(\n",
      "    (0-1): 2 x ParentChildFusionLayer()\n",
      "  )\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=16, bias=True)\n",
      "    (1): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 6.2573, -0.1835, -0.1707, -0.2310, -0.2280, -0.1361,  4.3763,  0.1117,\n",
       "         4.6189], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "\n",
    "class ParentChildFusionLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    A MessagePassing layer designed for tree-like graphs where each parent\n",
    "    has either exactly two children or none. For each parent node i, the\n",
    "    features of the parent and its two children (if present) are concatenated.\n",
    "\n",
    "    This layer does not use any attention or permutation-invariant\n",
    "    aggregation: child messages are collected explicitly and concatenated\n",
    "    in a fixed order. The user must ensure that each parent node has either\n",
    "    (0 or 2) incoming edges, and that the edge_index ordering encodes a\n",
    "    consistent left/right child order.\n",
    "\n",
    "    Input dimensions:\n",
    "        - Node feature dimension: in_dim\n",
    "        - Output feature dimension: out_dim\n",
    "\n",
    "    Output:\n",
    "        - New node embeddings of dimension out_dim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim):\n",
    "        # We do not use built-in aggregation (\"add\", \"mean\", ...) because\n",
    "        # we aggregate manually. Set aggr=None.\n",
    "            \n",
    "        # Each node will produce: [parent_features, child1, child2]\n",
    "        # If a node has no children, child features are zero-padded.\n",
    "        super().__init__(node_dim=0, aggr=None)\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def aggregate(self, inputs, index, ptr=None, dim_size=None):\n",
    "        \"\"\"\n",
    "        Collect exactly two child feature vectors per parent.\n",
    "\n",
    "        inputs:  (num_edges, in_dim)\n",
    "        index:   (num_edges,) target node for each edge\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (num_nodes, 2 * in_dim) containing the two\n",
    "            children features for each parent. Order is determined by\n",
    "            edge ordering and should be consistent in the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # Determine number of nodes from dim_size (preferred), fall back to index\n",
    "        if dim_size is not None:\n",
    "            num_nodes = dim_size\n",
    "        else:\n",
    "            num_nodes = int(index.max().item()) + 1\n",
    "\n",
    "        device = inputs.device\n",
    "\n",
    "        # Preallocate storage\n",
    "        children = torch.zeros(num_nodes, 2, self.in_dim, device=device)\n",
    "\n",
    "        # Compute for each edge its \"child slot\" 0 or 1\n",
    "        # Example: for index = [3,3,5,5], this produces [0,1,0,1]\n",
    "        slot = torch.zeros_like(index)\n",
    "        slot[1:] = (index[1:] == index[:-1]).long()\n",
    "\n",
    "        # Vectorized scatter operation\n",
    "        children[index, slot] = inputs\n",
    "\n",
    "        return children.reshape(num_nodes, 2 * self.in_dim)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"\n",
    "        aggr_out: (num_nodes, 2*in_dim) concatenated children features\n",
    "        x:        (num_nodes, in_dim)   parent features\n",
    "\n",
    "        Returns:\n",
    "            Fused parent representation → out_dim\n",
    "        \"\"\"\n",
    "        fused = torch.cat([x, aggr_out], dim=-1)\n",
    "        return fused\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x: (num_nodes, in_dim)\n",
    "        edge_index: (2, num_edges), where edges point child -> parent\n",
    "\n",
    "        Returns:\n",
    "            Updated node embeddings (num_nodes, out_dim)\n",
    "        \"\"\"\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "\n",
    "class RecipientFinder(nn.Module):\n",
    "    \"\"\"\n",
    "    A model that stacks several ParentChildFusionLayers followed by\n",
    "    fully connected layers for prediction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Dimensionality of the input node features.\n",
    "    hidden_channels : int\n",
    "        Dimensionality after the ParentChildFusionLayers.\n",
    "    num_fusion_layers : int\n",
    "        Number of ParentChildFusionLayers to apply sequentially.\n",
    "    dropout : float\n",
    "        Dropout probability for the fully connected classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels = 16,\n",
    "                 num_fusion_layers=2, num_fc_layers = 2, dropout=0.3):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # ----- Fusion Layers -----\n",
    "        self.fusion_layers = nn.ModuleList()\n",
    "        current_dim = in_channels\n",
    "\n",
    "        for _ in range(num_fusion_layers):\n",
    "            self.fusion_layers.append(ParentChildFusionLayer(in_dim=current_dim))\n",
    "            current_dim = current_dim * 3 # 3 is coming from one parent and two children. If there are no children it is filled with zeros.\n",
    "\n",
    "        # ----- Fully Connected Layers -----\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # First FC layer: (current_dim → hidden_channels) OR directly → 1\n",
    "        if num_fc_layers == 1:\n",
    "            self.fc_layers.append(nn.Linear(current_dim, 1))\n",
    "        else:\n",
    "            # First hidden layer\n",
    "            self.fc_layers.append(nn.Linear(current_dim, hidden_channels))\n",
    "            # Middle hidden FC layers\n",
    "            for _ in range(num_fc_layers - 2):\n",
    "                self.fc_layers.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "            # Final output layer\n",
    "            self.fc_layers.append(nn.Linear(hidden_channels, 1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Apply stacked fusion layers followed by linear classifiers.\n",
    "        \"\"\"\n",
    "\n",
    "        # ----- ParentChildFusionLayers -----\n",
    "        for layer in self.fusion_layers:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        # ----- Fully Connected Layers -----\n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = layer(x)\n",
    "            if i < len(self.fc_layers) - 1:\n",
    "                x = F.relu(x)\n",
    "\n",
    "        return x.view(-1)\n",
    "\n",
    "\n",
    "i = 0\n",
    "model = RecipientFinder(in_channels = data[i].x.shape[1])\n",
    "print(model)\n",
    "model(data[i].x, data[i].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75b5bee-f481-4ce0-8b12-81f3a8493d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Weight: 5.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6782/535982600.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.9381 | Acc: 0.948 | Prec: 0.304 | Rec: 0.529 | F1: 0.386\n",
      "Epoch 02 | Loss: 0.3411 | Acc: 0.951 | Prec: 0.316 | Rec: 0.511 | F1: 0.391\n",
      "Epoch 03 | Loss: 0.2868 | Acc: 0.956 | Prec: 0.338 | Rec: 0.445 | F1: 0.384\n",
      "Epoch 04 | Loss: 0.2643 | Acc: 0.958 | Prec: 0.343 | Rec: 0.398 | F1: 0.368\n",
      "Epoch 05 | Loss: 0.2512 | Acc: 0.956 | Prec: 0.353 | Rec: 0.512 | F1: 0.418\n",
      "Epoch 06 | Loss: 0.2412 | Acc: 0.964 | Prec: 0.400 | Rec: 0.365 | F1: 0.382\n",
      "Epoch 07 | Loss: 0.2390 | Acc: 0.952 | Prec: 0.342 | Rec: 0.597 | F1: 0.435\n",
      "Epoch 08 | Loss: 0.2379 | Acc: 0.955 | Prec: 0.350 | Rec: 0.534 | F1: 0.423\n",
      "Epoch 09 | Loss: 0.2286 | Acc: 0.967 | Prec: 0.455 | Rec: 0.339 | F1: 0.389\n",
      "Epoch 10 | Loss: 0.2286 | Acc: 0.952 | Prec: 0.336 | Rec: 0.565 | F1: 0.421\n",
      "Epoch 11 | Loss: 0.2237 | Acc: 0.961 | Prec: 0.395 | Rec: 0.485 | F1: 0.435\n",
      "Epoch 12 | Loss: 0.2263 | Acc: 0.950 | Prec: 0.332 | Rec: 0.630 | F1: 0.435\n",
      "Epoch 13 | Loss: 0.2268 | Acc: 0.946 | Prec: 0.325 | Rec: 0.690 | F1: 0.442\n",
      "Epoch 14 | Loss: 0.2172 | Acc: 0.940 | Prec: 0.301 | Rec: 0.710 | F1: 0.422\n",
      "Epoch 15 | Loss: 0.2291 | Acc: 0.950 | Prec: 0.338 | Rec: 0.656 | F1: 0.446\n",
      "Epoch 16 | Loss: 0.2227 | Acc: 0.930 | Prec: 0.283 | Rec: 0.836 | F1: 0.422\n",
      "Epoch 17 | Loss: 0.2197 | Acc: 0.970 | Prec: 0.532 | Rec: 0.097 | F1: 0.164\n",
      "Epoch 18 | Loss: 0.2135 | Acc: 0.954 | Prec: 0.353 | Rec: 0.588 | F1: 0.441\n",
      "Epoch 19 | Loss: 0.2168 | Acc: 0.951 | Prec: 0.343 | Rec: 0.638 | F1: 0.446\n",
      "Epoch 20 | Loss: 0.2223 | Acc: 0.931 | Prec: 0.286 | Rec: 0.820 | F1: 0.424\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# === 1. Modell, Optimizer, Loss ===\n",
    "model = RecipientFinder(in_channels=data[0].x.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Klassengewichte berechnen (gegen Ungleichgewicht)\n",
    "all_labels = torch.cat([g.y for g in data])\n",
    "ratio = (len(all_labels) - all_labels.sum()) / all_labels.sum()\n",
    "pos_weight = torch.tensor((ratio**0.5), dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "print(f\"Pos Weight: {pos_weight.item():.2f}\")\n",
    "\n",
    "# === 2. Training & Evaluation ===\n",
    "\n",
    "# Train/Test Split\n",
    "random.shuffle(data)\n",
    "split_idx = int(0.5 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "test_data = data[split_idx:]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(train_data, batch_size=8)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(out, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        preds = torch.sigmoid(out) > 0.5\n",
    "        total_correct += (preds == batch.y.bool()).sum().item()\n",
    "        total_nodes += batch.y.size(0)\n",
    "\n",
    "        # Metriken für Klasse 1\n",
    "        tp += ((preds == 1) & (batch.y == 1)).sum().item()\n",
    "        fp += ((preds == 1) & (batch.y == 0)).sum().item()\n",
    "        fn += ((preds == 0) & (batch.y == 1)).sum().item()\n",
    "\n",
    "    acc = total_correct / total_nodes\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "# === 3. Training starten ===\n",
    "for epoch in range(1, 21):\n",
    "    loss = train()\n",
    "    acc, prec, rec, f1 = evaluate(test_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Acc: {acc:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
