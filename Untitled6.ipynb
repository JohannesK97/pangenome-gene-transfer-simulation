{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b282e06-abd1-4626-b082-bac6dc2d0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def estimate_num_blocks(mat: np.ndarray, eps=0.05, min_block_size=1):\n",
    "    \"\"\"\n",
    "    Schätzt Anzahl rechteckiger Blöcke in der Matrix.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    mat : ndarray (size, size)\n",
    "        Symmetrische Matrix mit Blöcken und NaNs\n",
    "    eps : float\n",
    "        Schwellenwert für Ähnlichkeit (z. B. 0.1)\n",
    "    min_block_size : int\n",
    "        Minimale Fläche für einen Block (gegen Rauschen)\n",
    "\n",
    "    Rückgabe\n",
    "    --------\n",
    "    count : int\n",
    "        Geschätzte Blockanzahl\n",
    "    \"\"\"\n",
    "    visited = np.zeros_like(mat, dtype=bool)\n",
    "    size = mat.shape[0]\n",
    "    count = 0\n",
    "\n",
    "    def flood_fill(i, j, ref_val):\n",
    "        \"\"\"Füllt zusammenhängende Zellen mit ähnlichem Wert\"\"\"\n",
    "        stack = [(i, j)]\n",
    "        region = []\n",
    "\n",
    "        while stack:\n",
    "            x, y = stack.pop()\n",
    "            if (\n",
    "                0 <= x < size and 0 <= y < size\n",
    "                and not visited[x, y]\n",
    "                and not np.isnan(mat[x, y])\n",
    "                and abs(mat[x, y] - ref_val) < eps\n",
    "            ):\n",
    "                visited[x, y] = True\n",
    "                region.append((x, y))\n",
    "                # Nachbarn hinzufügen (4-connectivity)\n",
    "                stack.extend([\n",
    "                    (x+1, y), (x-1, y),\n",
    "                    (x, y+1), (x, y-1)\n",
    "                ])\n",
    "        return region\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(i+1, size):  # Nur obere Hälfte\n",
    "            if not visited[i, j] and not np.isnan(mat[i, j]):\n",
    "                region = flood_fill(i, j, mat[i, j])\n",
    "                if len(region) >= min_block_size:\n",
    "                    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def generate_block_matrix_with_gaps(size=100,\n",
    "                                    noise_level=0.0,\n",
    "                                    p_drop=0.15,\n",
    "                                    p_group=0.5,\n",
    "                                    max_group_size=4,\n",
    "                                    fill_value=np.nan,\n",
    "                                    lam = 5,\n",
    "                                    rho = 0,\n",
    "                                    rho_expand = 4):\n",
    "    \"\"\"\n",
    "    Erstellt eine symmetrische Block‑Matrix (‑1…1) und löscht hinterher\n",
    "    zufällig Spalten + zugehörige Zeilen (= Informationsverlust).\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    size : int\n",
    "        Seitenlänge der quadratischen Matrix.\n",
    "    num_blocks : int\n",
    "        Wie viele rechteckige Blöcke erzeugt werden.\n",
    "    noise_level : float\n",
    "        Standardabweichung des Rauschens in Block‑ bzw. Hintergrundfeldern.\n",
    "    p_drop : float\n",
    "        Wahrscheinlichkeit, dass eine gegebene Spalte entfernt wird (0–1).\n",
    "    p_group : float\n",
    "        Wahrscheinlichkeit, dass nach dem Entfernen einer Spalte\n",
    "        *zusätzliche* benachbarte Spalten als zusammenhängende Gruppe\n",
    "        entfernt werden.\n",
    "    max_group_size : int\n",
    "        Obergrenze für die Größe einer entfernten Spaltengruppe.\n",
    "    fill_value : float\n",
    "        Wert, mit dem gelöschte Zellen aufgefüllt werden\n",
    "        (NaN, 0, −999 … je nach Downstream‑Modell).\n",
    "\n",
    "    Rückgabe\n",
    "    --------\n",
    "    mat : ndarray, shape (size, size)\n",
    "        Symmetrische Matrix mit evtl. fehlenden Spalten/Zeilen.\n",
    "    num_blocks : int\n",
    "        Tatsächlich verwendete Block‑Anzahl (unverändert).\n",
    "    removed_idx : list[int]\n",
    "        Sortierte Liste der entfernten Spalten/Zeilen‑Indizes.\n",
    "    \"\"\"\n",
    "    # -------- 1) Grundmatrix mit Blöcken erzeugen -------- #\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # -------- 3) Matrix initialisieren -------- #\n",
    "    mat = np.full((size, size), fill_value, dtype=float)\n",
    "    used = np.full((size, size), False, dtype=float)\n",
    "    num_blocks = 0\n",
    "\n",
    "    rho = rng.exponential(rho)\n",
    "    rho_expand = rng.exponential(rho_expand)\n",
    "    \n",
    "\n",
    "    # -------- 4) Blöcke füllen und symmetrisch setzen -------- #\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(i+1, size):\n",
    "            if used[i,j] == False:\n",
    "                block_breite = min(j - i, rng.poisson(rho) + 1, size - i)\n",
    "                block_tiefe = min(j-i, rng.poisson(rho) + 1, size - j)\n",
    "                val = rng.uniform(-1, 1)\n",
    "                block = rng.normal(val, noise_level, size=(block_breite, block_tiefe))\n",
    "                num_blocks += 1\n",
    "                # Grenzindizes berechnen\n",
    "                r0, r1 = i, i + block_breite\n",
    "                c0, c1 = j, j + block_tiefe\n",
    "                \n",
    "                # Obere Hälfte (originaler Block)\n",
    "                mat[r0:r1, c0:c1] = block\n",
    "                \n",
    "                # Untere Hälfte (transponiert einschreiben)\n",
    "                mat[c0:c1, r0:r1] = block.T      # hier wird auf echte Slice-Koordinaten geschrieben\n",
    "                used[i:(i+block_breite), j:(j+block_tiefe)] = True\n",
    "\n",
    "    for i in range(size):\n",
    "        mat[i,i] = 0\n",
    "\n",
    "    # -------- 2) Spalten-/Zeilenlöschung vorbereiten -------- #\n",
    "    n_initial = min(size, max(0, rng.poisson(rho)))\n",
    "    candidates = rng.choice(np.arange(size), size=n_initial, replace=False)\n",
    "    \n",
    "    deleted_rows = []\n",
    "\n",
    "    for idx in candidates:\n",
    "        deleted_rows.append(idx)\n",
    "\n",
    "        # Links erweitern\n",
    "        left_expand = rng.poisson(rho_expand)\n",
    "        left_indices = [i for i in range(idx - left_expand, idx) if 0 <= i < size]\n",
    "        deleted_rows.extend(left_indices)\n",
    "\n",
    "        # Rechts erweitern\n",
    "        right_expand = rng.poisson(rho_expand)\n",
    "        right_indices = [i for i in range(idx + 1, idx + 1 + right_expand) if 0 <= i < size]\n",
    "        deleted_rows.extend(right_indices)\n",
    "\n",
    "    # -------- 3) Spalten und Zeilen auf fill_value setzen -------- #\n",
    "    if deleted_rows:\n",
    "        mat[:, deleted_rows] = fill_value\n",
    "        mat[deleted_rows, :] = fill_value\n",
    "\n",
    "    num_blocks = estimate_num_blocks(mat)\n",
    "    return mat, torch.tensor(num_blocks, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8838367e-dba1-4fdb-946d-bd4bcae4cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_blocks_sym(mat: np.ndarray, threshold: float = 0.05):\n",
    "    \"\"\"\n",
    "    Schnelle Blocksuche in quadratischer symmetrischer Matrix.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    mat : np.ndarray (N, N)\n",
    "        Symmetrische Matrix mit beliebigen Werten.\n",
    "    threshold : float\n",
    "        Maximaler Wertunterschied für 'gleichartigen' Block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_blocks : int\n",
    "        Anzahl gefundener Blöcke.\n",
    "    labels : np.ndarray (N, N)\n",
    "        Ganzzahlige Beschriftung je Zelle (0..num_blocks-1).\n",
    "    \"\"\"\n",
    "    assert mat.ndim == 2 and mat.shape[0] == mat.shape[1], \"Matrix muss quadratisch sein.\"\n",
    "    n = mat.shape[0]\n",
    "\n",
    "    # 1. Label-Puffer und Union-Find-Struktur vorbereiten\n",
    "    labels = -np.ones_like(mat, dtype=int)\n",
    "    parent = []           # parent[i] = root‑Index des Blocks i\n",
    "    ranks  = []           # Union‑by‑rank\n",
    "\n",
    "    def find(u):\n",
    "        \"\"\"Pfadkompression.\"\"\"\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        \"\"\"Vereinigt zwei Blöcke (root‑IDs).\"\"\"\n",
    "        ru, rv = find(u), find(v)\n",
    "        if ru == rv:\n",
    "            return\n",
    "        # Union by rank\n",
    "        if ranks[ru] < ranks[rv]:\n",
    "            parent[ru] = rv\n",
    "        elif ranks[ru] > ranks[rv]:\n",
    "            parent[rv] = ru\n",
    "        else:\n",
    "            parent[rv] = ru\n",
    "            ranks[ru] += 1\n",
    "\n",
    "    # 2. Einmal über Matrix laufen (oben‑links‑Nachbarn reichen)\n",
    "    next_label = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            val = mat[i, j]\n",
    "\n",
    "            # Kandidaten‑Nachbarn: oben (i‑1,j) und links (i,j‑1)\n",
    "            candidates = []\n",
    "            if i > 0 and abs(val - mat[i-1, j]) <= threshold:\n",
    "                candidates.append(labels[i-1, j])\n",
    "            if j > 0 and abs(val - mat[i, j-1]) <= threshold:\n",
    "                candidates.append(labels[i, j-1])\n",
    "\n",
    "            # Keine passenden Nachbarn → neuer Block\n",
    "            if not candidates:\n",
    "                labels[i, j] = next_label\n",
    "                parent.append(next_label)\n",
    "                ranks.append(0)\n",
    "                next_label += 1\n",
    "            else:\n",
    "                # Nutze erstes passendes Label\n",
    "                lbl = candidates[0]\n",
    "                labels[i, j] = lbl\n",
    "                # Vereinige evtl. unterschiedliche Nachbarn\n",
    "                for other in candidates[1:]:\n",
    "                    if other != lbl:\n",
    "                        union(lbl, other)\n",
    "\n",
    "    # 3. Zweite Phase: Root‑Labels & Umnummerierung\n",
    "    root_map = {}\n",
    "    new_label = 0\n",
    "    for idx in range(next_label):\n",
    "        root = find(idx)\n",
    "        if root not in root_map:\n",
    "            root_map[root] = new_label\n",
    "            new_label += 1\n",
    "\n",
    "    # labels aktualisieren\n",
    "    it = np.nditer(labels, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        it[0][...] = root_map[find(it[0].item())]\n",
    "        it.iternext()\n",
    "\n",
    "    return new_label, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97f1042b-75c0-4509-ae91-f98edd7d6ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th=0.0: Blöcke=5050\n",
      "th=0.025: Blöcke=4808\n",
      "th=0.05: Blöcke=4581\n",
      "th=0.07500000000000001: Blöcke=4339\n",
      "th=0.1: Blöcke=4125\n",
      "th=0.125: Blöcke=3925\n",
      "th=0.15000000000000002: Blöcke=3720\n",
      "th=0.17500000000000002: Blöcke=3529\n",
      "th=0.2: Blöcke=3353\n",
      "th=0.225: Blöcke=3180\n",
      "th=0.25: Blöcke=3020\n",
      "th=0.275: Blöcke=2859\n",
      "th=0.30000000000000004: Blöcke=2719\n",
      "th=0.325: Blöcke=2566\n",
      "th=0.35000000000000003: Blöcke=2420\n",
      "th=0.375: Blöcke=2298\n",
      "th=0.4: Blöcke=2143\n",
      "th=0.42500000000000004: Blöcke=2021\n",
      "th=0.45: Blöcke=1912\n",
      "th=0.47500000000000003: Blöcke=1785\n",
      "th=0.5: Blöcke=1677\n",
      "th=0.525: Blöcke=1581\n",
      "th=0.55: Blöcke=1488\n",
      "th=0.5750000000000001: Blöcke=1388\n",
      "th=0.6000000000000001: Blöcke=1300\n",
      "th=0.625: Blöcke=1218\n",
      "th=0.65: Blöcke=1149\n",
      "th=0.675: Blöcke=1074\n",
      "th=0.7000000000000001: Blöcke=988\n",
      "th=0.7250000000000001: Blöcke=912\n",
      "th=0.75: Blöcke=862\n",
      "th=0.775: Blöcke=804\n",
      "th=0.8: Blöcke=743\n",
      "th=0.8250000000000001: Blöcke=684\n",
      "th=0.8500000000000001: Blöcke=648\n",
      "th=0.875: Blöcke=607\n",
      "th=0.9: Blöcke=549\n",
      "th=0.925: Blöcke=503\n",
      "th=0.9500000000000001: Blöcke=470\n",
      "th=0.9750000000000001: Blöcke=439\n",
      "th=1.0: Blöcke=402\n",
      "0.0030002593994140625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9998343400533789"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mat = generate_block_matrix_with_gaps(size = 100)[0]\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "#print(matrix[0])\n",
    "\n",
    "start_time = time.time()\n",
    "thresholds = np.arange(0, 1.0001, 0.025)\n",
    "results = count_blocks_sym(mat, thresholds)\n",
    "for th, (lab, k) in zip(thresholds, results):\n",
    "    print(f\"th={th}: Blöcke={k}\")\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)\n",
    "\n",
    "np.max(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "716c62f7-cee1-41fa-9741-18e6847e1ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene Blöcke: 17664\n",
      "0.03799796104431152\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage as ndi\n",
    "\n",
    "threshold = 0.01\n",
    "n = 1000\n",
    "mat = generate_block_matrix_with_gaps(size = n)[0]\n",
    "\n",
    "start_time = time.time()\n",
    "mask = ~np.isnan(mat)\n",
    "# NaNs maskieren\n",
    "valid = ~np.isnan(mat)\n",
    "\n",
    "# Eine binäre Maske, wo Werte innerhalb des Schwellenwerts zu ihren Nachbarn ähnlich sind\n",
    "# Wir initialisieren die Maske als False, dann setzen wir nur gültige Vergleichsergebnisse\n",
    "similar = np.zeros_like(mat, dtype=bool)\n",
    "\n",
    "# Vergleiche zu Nachbarn nach oben, links, unten, rechts\n",
    "for dx, dy in [(-1,0), (0,-1), (1,0), (0,1)]:\n",
    "    shifted = np.roll(mat, shift=(dx, dy), axis=(0,1))\n",
    "    shifted_valid = np.roll(valid, shift=(dx, dy), axis=(0,1))\n",
    "    cmp_mask = (np.abs(mat - shifted) < threshold) & valid & shifted_valid\n",
    "    similar |= cmp_mask\n",
    "\n",
    "# Verbundene Bereiche labeln\n",
    "structure = np.array([[0,1,0],\n",
    "                      [1,1,1],\n",
    "                      [0,1,0]])\n",
    "\n",
    "labels, num = ndi.label(similar, structure=structure)\n",
    "\n",
    "print(f\"Gefundene Blöcke: {num}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e02c3e1-b190-42c3-859b-af4470f978b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from typing import Union, Sequence, List, Tuple\n",
    "\n",
    "@njit                       # ---------- Kern für *einen* threshold ----------\n",
    "def _count_blocks_single(mat, idx, threshold):\n",
    "    n = idx.size\n",
    "    label_matrix = -np.ones((n, n), dtype=np.int32)\n",
    "    num_labels   = 0\n",
    "\n",
    "    for ii in range(n):\n",
    "        i = idx[ii]\n",
    "        for jj in range(ii, n):\n",
    "            j = idx[jj]\n",
    "            if ii == 0 and jj == 0:\n",
    "                label_matrix[ii, jj] = 0\n",
    "                num_labels += 1\n",
    "            elif ii == 0:\n",
    "                if abs(mat[i, j] - mat[i, idx[jj-1]]) < threshold:\n",
    "                    label_matrix[ii, jj] = label_matrix[ii, jj-1]\n",
    "                else:\n",
    "                    label_matrix[ii, jj] = num_labels\n",
    "                    num_labels += 1\n",
    "            else:\n",
    "                if abs(mat[i, j] - mat[idx[ii-1], j]) < threshold:\n",
    "                    label_matrix[ii, jj] = label_matrix[ii-1, jj]\n",
    "                elif abs(mat[i, j] - mat[i, idx[jj-1]]) < threshold:\n",
    "                    label_matrix[ii, jj] = label_matrix[ii, jj-1]\n",
    "                else:\n",
    "                    label_matrix[ii, jj] = num_labels\n",
    "                    num_labels += 1\n",
    "    return label_matrix, num_labels\n",
    "\n",
    "\n",
    "# ----------------------- Benutzer‑Funktion -----------------------\n",
    "def count_blocks_sym(mat: np.ndarray,\n",
    "                     threshold: Union[float, Sequence[float]] = 0.05\n",
    "                    ) -> List[Tuple[np.ndarray, int]]:\n",
    "    \"\"\"\n",
    "    Führe die Blockzählung für einen oder mehrere threshold‑Werte durch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : np.ndarray (N, N)\n",
    "        Symmetrische Matrix mit NaNs.\n",
    "    threshold : float | list[float]\n",
    "        Einzelner Grenzwert oder Liste davon.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : list[(label_matrix, num_labels)]\n",
    "        Liste in derselben Reihenfolge wie threshold(s).\n",
    "    \"\"\"\n",
    "    assert mat.ndim == 2 and mat.shape[0] == mat.shape[1], \"Matrix muss quadratisch sein.\"\n",
    "    thresholds = np.atleast_1d(threshold).astype(np.float64)\n",
    "\n",
    "    # Vorarbeit außerhalb der Schleife\n",
    "    idx = np.where(~np.isnan(mat[0]))[0]\n",
    "\n",
    "    results = []\n",
    "    for th in thresholds:\n",
    "        labels, k = _count_blocks_single(mat, idx, th)\n",
    "        results.append((labels, int(k)))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c9cdad8-da75-4acd-815e-25f94ea6c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_blocks_sym(mat: np.ndarray, threshold: float = 0.05):\n",
    "    \"\"\"\n",
    "    Schnelle Blocksuche in quadratischer symmetrischer Matrix.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    mat : np.ndarray (N, N)\n",
    "        Symmetrische Matrix mit beliebigen Werten.\n",
    "    threshold : float\n",
    "        Maximaler Wertunterschied für 'gleichartigen' Block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_blocks : int\n",
    "        Anzahl gefundener Blöcke.\n",
    "    labels : np.ndarray (N, N)\n",
    "        Ganzzahlige Beschriftung je Zelle (0..num_blocks-1).\n",
    "    \"\"\"\n",
    "    assert mat.ndim == 2 and mat.shape[0] == mat.shape[1], \"Matrix muss quadratisch sein.\"\n",
    "    n = mat.shape[0]\n",
    "\n",
    "    gene_presence_vector = ~np.isnan(mat[0])\n",
    "    matrix = mat[np.ix_(gene_presence_vector, gene_presence_vector)]\n",
    "    n = sum(gene_presence_vector)\n",
    "\n",
    "    label_matrix = np.full((n, n), np.nan)\n",
    "    number_of_labels = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == 0 and j == 0:\n",
    "                label_matrix[i,j] = 0\n",
    "                number_of_labels += 1\n",
    "            elif i == 0: # j != 0\n",
    "                if abs(matrix[i,j] - matrix[i,j-1]) < threshold:\n",
    "                    label_matrix[i,j] = label_matrix[i,j-1]\n",
    "                else:\n",
    "                    label_matrix[i,j] = number_of_labels\n",
    "                    number_of_labels += 1\n",
    "            else:\n",
    "                if abs(matrix[i,j] - matrix[i-1,j]) < threshold:\n",
    "                    label_matrix[i,j] = label_matrix[i-1,j]\n",
    "                elif abs(matrix[i,j] - matrix[i,j-1]) < threshold:\n",
    "                    label_matrix[i,j] = label_matrix[i,j-1]\n",
    "                else:\n",
    "                    label_matrix[i,j] = number_of_labels\n",
    "                    number_of_labels += 1\n",
    "                    \n",
    "    return label_matrix, number_of_labels\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcdbc277-08c5-47c9-9c66-4afd009535c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_presence_vector = ~np.isnan(matrix[0])\n",
    "#matrix = matrix[np.ix_(gene_presence_vector, gene_presence_vector)]\n",
    "sum(gene_presence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a7069da0-0ec2-4a48-885c-8cd60796bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BlockMatrixDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 n_samples=10_000,\n",
    "                 size=100,\n",
    "                 noise_level=0.05,\n",
    "                 lam=3,\n",
    "                 rho=1,\n",
    "                 rho_expand=1,\n",
    "                 seed=None):\n",
    "        self.size = size\n",
    "        self.rng  = np.random.default_rng(seed)\n",
    "        self.mats = []\n",
    "        self.labels = []\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            mat, n_blocks = generate_block_matrix_with_gaps(\n",
    "                size=size,\n",
    "                noise_level=noise_level,\n",
    "                lam=lam,\n",
    "                rho=rho,\n",
    "                rho_expand=rho_expand\n",
    "            )\n",
    "            # Maske für fehlende Werte\n",
    "            mask = np.isnan(mat).astype(float)\n",
    "            # fehlende Einträge 0 setzen (oder Mittelwert)\n",
    "            mat[np.isnan(mat)] = 0.0\n",
    "\n",
    "            # [C, H, W]  -> 2 Kanäle: Matrix + Maske\n",
    "            sample = np.stack([mat, mask])\n",
    "            self.mats.append(sample.astype(np.float32))\n",
    "            self.labels.append(float(n_blocks))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.mats[idx])\n",
    "        y = torch.tensor(self.labels[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "407bcacb-8282-4556-bcfd-7f44eb3b9f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BlockCounterCNN(nn.Module):\n",
    "    def __init__(self, n_channels=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, 16, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool  = nn.AdaptiveAvgPool2d(1)   # [64,1,1]\n",
    "        self.fc1   = nn.Linear(64, 128)        # <‑‑ fix\n",
    "        self.head  = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)              # [batch, 64, 1, 1]\n",
    "        x = x.view(x.size(0), -1)       # → [batch, 64]\n",
    "        print(x.shape)   # sollte (batch_size, 64)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        return self.head(x).squeeze(1)\n",
    "\n",
    "def run_simulations(simulator, prior, num_simulations):\n",
    "    thetas, xs = [], []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        sim = generate_block_matrix_with_gaps()\n",
    "        sim[0][np.isnan(sim[0])] = 0.0\n",
    "        thetas.append(sim[1])  # num_blocks\n",
    "        xs.append(torch.tensor(sim[0], dtype=torch.float32))  # [size, size]\n",
    "\n",
    "    theta = torch.tensor(thetas, dtype=torch.float32).unsqueeze(1)  # [N, 1]\n",
    "    x = torch.stack(xs, dim=0)  # [N, H, W]\n",
    "    x = x.unsqueeze(1)\n",
    "    return theta, x\n",
    "\n",
    "\n",
    "# Training:\n",
    "from sbi.utils import BoxUniform\n",
    "\n",
    "prior = BoxUniform(low=torch.tensor([1.0]), high=torch.tensor([4000.0]))\n",
    "theta, x = run_simulations(simulator, prior, num_simulations=10)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6fe6cff7-2dab-4d64-9331-b949f52e8829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "torch.Size([2, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Debug hint: The simulated data x has 3 dimensions.\n            With default settings, sbi cannot deal with multidimensional simulations.\n            Make sure to use an embedding net that reduces the dimensionality, e.g., a\n            CNN in case of images, or change the simulator to return one-dimensional x.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\sbi\\utils\\user_input_checks.py:759\u001b[0m, in \u001b[0;36mtest_posterior_net_for_multi_d_x\u001b[1;34m(net, theta, x)\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(net, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    757\u001b[0m         \u001b[38;5;66;03m# This only is checked for density estimators, not for classifiers and\u001b[39;00m\n\u001b[0;32m    758\u001b[0m         \u001b[38;5;66;03m# others\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m         \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m rte:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\sbi\\neural_nets\\estimators\\nflows_flow.py:109\u001b[0m, in \u001b[0;36mNFlowsFlow.log_prob\u001b[1;34m(self, input, condition)\u001b[0m\n\u001b[0;32m    107\u001b[0m condition \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39mrepeat(input_sample_dim, \u001b[38;5;241m*\u001b[39mones_for_event_dims)\n\u001b[1;32m--> 109\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_probs\u001b[38;5;241m.\u001b[39mreshape((input_sample_dim, input_batch_dim))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\nflows\\distributions\\base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of input items must be equal to number of context items.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m         )\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\nflows\\flows\\base.py:39\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     38\u001b[0m embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_net(context)\n\u001b[1;32m---> 39\u001b[0m noise, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution\u001b[38;5;241m.\u001b[39mlog_prob(noise, context\u001b[38;5;241m=\u001b[39membedded_context)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\nflows\\transforms\\base.py:56\u001b[0m, in \u001b[0;36mCompositeTransform.forward\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     55\u001b[0m funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transforms\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\nflows\\transforms\\base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[1;34m(inputs, funcs, context)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[1;32m---> 50\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     total_logabsdet \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logabsdet\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\nflows\\transforms\\autoregressive.py:38\u001b[0m, in \u001b[0;36mAutoregressiveTransform.forward\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 38\u001b[0m     autoregressive_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoregressive_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elementwise_forward(inputs, autoregressive_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\nflows\\transforms\\made.py:277\u001b[0m, in \u001b[0;36mMADE.forward\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     temps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_residual_blocks:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2 and 1x64)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[246], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m inference \u001b[38;5;241m=\u001b[39m SNPE(prior\u001b[38;5;241m=\u001b[39mprior, density_estimator\u001b[38;5;241m=\u001b[39mneural_posterior)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Simuliere 10.000 θ,x-Paare\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m density_estimator \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_simulations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m posterior \u001b[38;5;241m=\u001b[39m inference\u001b[38;5;241m.\u001b[39mbuild_posterior(density_estimator)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\sbi\\inference\\trainers\\npe\\npe_c.py:189\u001b[0m, in \u001b[0;36mNPE_C.train\u001b[1;34m(self, num_atoms, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, use_combined_loss, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_non_atomic_loss:\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;66;03m# Take care of z-scoring, pre-compute and store prior terms.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_state_for_mog_proposal()\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\sbi\\inference\\trainers\\npe\\npe_base.py:335\u001b[0m, in \u001b[0;36mPosteriorEstimator.train\u001b[1;34m(self, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m     theta \u001b[38;5;241m=\u001b[39m reshape_to_sample_batch_event(\n\u001b[0;32m    332\u001b[0m         theta\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neural_net\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[0;32m    333\u001b[0m     )\n\u001b[0;32m    334\u001b[0m     x \u001b[38;5;241m=\u001b[39m reshape_to_batch_event(x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neural_net\u001b[38;5;241m.\u001b[39mcondition_shape)\n\u001b[1;32m--> 335\u001b[0m     \u001b[43mtest_posterior_net_for_multi_d_x\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neural_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m theta, x\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Move entire net to device for training.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pangenome-gene-transfer-simulation\\Lib\\site-packages\\sbi\\utils\\user_input_checks.py:772\u001b[0m, in \u001b[0;36mtest_posterior_net_for_multi_d_x\u001b[1;34m(net, theta, x)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    770\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrte\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Debug hint: The simulated data x has 3 dimensions.\n            With default settings, sbi cannot deal with multidimensional simulations.\n            Make sure to use an embedding net that reduces the dimensionality, e.g., a\n            CNN in case of images, or change the simulator to return one-dimensional x.\n            "
     ]
    }
   ],
   "source": [
    "from sbi.utils import BoxUniform\n",
    "\n",
    "# Anzahl der Blöcke zwischen 1 und 30\n",
    "import sbi\n",
    "from sbi import utils\n",
    "from sbi.neural_nets import posterior_nn\n",
    "from sbi.inference import SNPE\n",
    "\n",
    "\n",
    "embedding_net = BlockCounterCNN()\n",
    "neural_posterior = posterior_nn(\n",
    "    model=\"maf\",\n",
    "    embedding_net=embedding_net,\n",
    "    hidden_features=64,\n",
    "    num_transforms=4\n",
    ")\n",
    "inference = SNPE(prior=prior, density_estimator=neural_posterior)\n",
    "\n",
    "# Simuliere 10.000 θ,x-Paare\n",
    "density_estimator = inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior(density_estimator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "64fc6f05-1616-400b-aa9e-8f3088652ef0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_block_matrix_with_gaps() got an unexpected keyword argument 'num_blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[237], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mat, true_num_blocks \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_block_matrix_with_gaps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m mat[np\u001b[38;5;241m.\u001b[39misnan(mat)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m x_obs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(mat, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mTypeError\u001b[0m: generate_block_matrix_with_gaps() got an unexpected keyword argument 'num_blocks'"
     ]
    }
   ],
   "source": [
    "mat, true_num_blocks = generate_block_matrix_with_gaps(num_blocks=7)\n",
    "mat[np.isnan(mat)] = 0\n",
    "x_obs = torch.tensor(mat, dtype=torch.float32).flatten()\n",
    "\n",
    "# Posterior auswerten\n",
    "posterior_samples = posterior.sample((1_000,), x=x_obs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(posterior_samples.numpy(), bins=30, density=True)\n",
    "plt.axvline(true_num_blocks, color='r', linestyle='--')\n",
    "plt.title(\"Posterior über Blockanzahl\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a39b3-b742-4f4c-a09c-5413fca7b5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
